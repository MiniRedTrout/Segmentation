{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 13734718,
          "sourceType": "datasetVersion",
          "datasetId": 8738907
        }
      ],
      "dockerImageVersionId": 31192,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiniRedTrout/Segmentation/blob/main/notebook4e08fe2ac5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импорт библиотек"
      ],
      "metadata": {
        "id": "KfVqj6hhJWaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T07:29:31.131600Z",
          "iopub.execute_input": "2025-11-15T07:29:31.131962Z",
          "iopub.status.idle": "2025-11-15T07:29:38.173868Z",
          "shell.execute_reply.started": "2025-11-15T07:29:31.131926Z",
          "shell.execute_reply": "2025-11-15T07:29:38.173001Z"
        },
        "id": "AbrPBBBBObnY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Путь датасета с kaggle"
      ],
      "metadata": {
        "id": "G9XJZ0byJaYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"miniredtrout/abdominalaorta\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1y9iTbfQQXr",
        "outputId": "7824adc3-7f19-4f9a-9c76-a58ac5bda621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'abdominalaorta' dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "35HxSbGIRI_2",
        "outputId": "48eb4e6e-21a0-4cce-f5e7-e163655837b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/kaggle/input/abdominalaorta'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hydra-core omegaconf\n",
        "import hydra\n",
        "from omegaconf import DictConfig, OmegaConf\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dnAHsMaOtm5",
        "outputId": "5773b30f-ee5d-48fc-ce59-edded26e5488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.12/dist-packages (1.3.2)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from hydra-core) (25.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf) (6.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install clearml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOzioQ7gdfYq",
        "outputId": "a2e57577-f6b8-4fae-b5fa-bb77c8a0a57b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: clearml in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: attrs>=18.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (25.4.0)\n",
            "Requirement already satisfied: furl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.1.4)\n",
            "Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (4.25.1)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.0.2)\n",
            "Requirement already satisfied: pathlib2>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.3.7.post1)\n",
            "Requirement already satisfied: psutil>=3.4.2 in /usr/local/lib/python3.12/dist-packages (from clearml) (5.9.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from clearml) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.9.0.post0)\n",
            "Requirement already satisfied: pyjwt<2.11.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.10.1)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.12/dist-packages (from clearml) (6.0.3)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.5.0)\n",
            "Requirement already satisfied: Pillow>=10.3.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (11.3.0)\n",
            "Requirement already satisfied: referencing<0.40 in /usr/local/lib/python3.12/dist-packages (from clearml) (0.37.0)\n",
            "Requirement already satisfied: requests>=2.32.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.32.4)\n",
            "Requirement already satisfied: orderedmultidict>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from furl>=2.0.0->clearml) (1.0.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6.0->clearml) (2025.9.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6.0->clearml) (0.28.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing<0.40->clearml) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.0->clearml) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.0->clearml) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.0->clearml) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
        "%env CLEARML_API_HOST=https://api.clear.ml\n",
        "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
        "%env CLEARML_API_ACCESS_KEY=XGMS61QRIXH7G4URU0X7VGTDAIQUVE\n",
        "%env CLEARML_API_SECRET_KEY=3mpOB_Br37BLBntBoUvtxmfbBfmkbkdfRUYGje8GfL1gwe_ufJd1w4UzuQWOPaAtTWE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUj8P68pvOai",
        "outputId": "d8b2fdfd-8456-475f-d7dd-ea51330257d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CLEARML_WEB_HOST=https://app.clear.ml/\n",
            "env: CLEARML_API_HOST=https://api.clear.ml\n",
            "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
            "env: CLEARML_API_ACCESS_KEY=XGMS61QRIXH7G4URU0X7VGTDAIQUVE\n",
            "env: CLEARML_API_SECRET_KEY=3mpOB_Br37BLBntBoUvtxmfbBfmkbkdfRUYGje8GfL1gwe_ufJd1w4UzuQWOPaAtTWE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from clearml import Task, Logger"
      ],
      "metadata": {
        "id": "6_SELnD-dYv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import hydra\n",
        "from omegaconf import DictConfig, OmegaConf\n",
        "\n",
        "config_dir = '/content/drive/MyDrive/segmentation_project/config'\n",
        "\n",
        "# Очистим и пересоздадим папку\n",
        "import shutil\n",
        "if os.path.exists(config_dir):\n",
        "    shutil.rmtree(config_dir)\n",
        "\n",
        "os.makedirs(config_dir, exist_ok=True)\n",
        "\n",
        "simple_config = \"\"\"\n",
        "training:\n",
        "  batch_size: 16\n",
        "  epochs: 40\n",
        "  learning_rate: 0.0002\n",
        "  optimizer: \"AdamW\"\n",
        "  weight_decay: 0.01\n",
        "\n",
        "data:\n",
        "  original_images_dir: \"/kaggle/input/abdominalaorta/images\"\n",
        "  original_labels_dir: \"/kaggle/input/abdominalaorta/labels\"\n",
        "  output_base_dir: \"/content/base_patients\"\n",
        "  test_size: 0.2\n",
        "  random_state: 42\n",
        "  image_size: 256\n",
        "  num_workers: 2\n",
        "\n",
        "model:\n",
        "  in_channel: 1\n",
        "  out_channel: 2\n",
        "\n",
        "transforms:\n",
        "  image_size: 256\n",
        "\"\"\"\n",
        "\n",
        "with open(f'{config_dir}/config.yaml', 'w') as f:\n",
        "    f.write(simple_config)\n",
        "\n",
        "print(\"✅ Простой конфиг создан!\")\n",
        "\n",
        "def load_hydra_config():\n",
        "    config_path = \"/content/drive/MyDrive/segmentation_project/config\"\n",
        "    config_name = \"config\"\n",
        "\n",
        "    with hydra.initialize_config_dir(config_dir=config_path, version_base=\"1.2\"):\n",
        "        cfg = hydra.compose(config_name=config_name)\n",
        "\n",
        "    # ОТКЛЮЧАЕМ STRICT MODE ПРОГРАММНО\n",
        "    OmegaConf.set_struct(cfg, False)\n",
        "\n",
        "    return cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3J-8nzvrbqu",
        "outputId": "f90132cd-94b5-415d-f3de-225ccc9a82a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Простой конфиг создан!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разделение на train test выборку по пациентам"
      ],
      "metadata": {
        "id": "DxpjPceMJe3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_test_split_by_patient():\n",
        "    cfg = load_hydra_config()\n",
        "    patient_folders = []\n",
        "    for folder in os.listdir(cfg.data.original_images_dir):\n",
        "        folder_path = os.path.join(cfg.data.original_images_dir, folder)\n",
        "        if (os.path.isdir(folder_path) and\n",
        "            os.path.exists(os.path.join(cfg.data.original_labels_dir, folder))):\n",
        "            patient_folders.append(folder)\n",
        "\n",
        "    train_patients, test_patients = train_test_split(\n",
        "        patient_folders,\n",
        "        test_size=cfg.data.test_size,\n",
        "        random_state=cfg.data.random_state\n",
        "    )\n",
        "\n",
        "    train_images_dir = os.path.join(cfg.data.output_base_dir, 'train', 'images')\n",
        "    train_labels_dir = os.path.join(cfg.data.output_base_dir, 'train', 'labels')\n",
        "    test_images_dir = os.path.join(cfg.data.output_base_dir, 'test', 'images')\n",
        "    test_labels_dir = os.path.join(cfg.data.output_base_dir, 'test', 'labels')\n",
        "\n",
        "    for dir_path in [train_images_dir, train_labels_dir, test_images_dir, test_labels_dir]:\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "    def copy_patient_files(patients, src_images_dir, src_labels_dir, dst_images_dir, dst_labels_dir):\n",
        "        total_files = 0\n",
        "        for patient in patients:\n",
        "            patient_images_dir = os.path.join(src_images_dir, patient)\n",
        "            patient_labels_dir = os.path.join(src_labels_dir, patient)\n",
        "\n",
        "            for file in os.listdir(patient_images_dir):\n",
        "                if file.endswith('.png'):\n",
        "                    src_image_path = os.path.join(patient_images_dir, file)\n",
        "                    dst_image_path = os.path.join(dst_images_dir, f\"{patient}_{file}\")\n",
        "                    shutil.copy2(src_image_path, dst_image_path)\n",
        "\n",
        "                    src_label_path = os.path.join(patient_labels_dir, file)\n",
        "                    dst_label_path = os.path.join(dst_labels_dir, f\"{patient}_{file}\")\n",
        "                    shutil.copy2(src_label_path, dst_label_path)\n",
        "\n",
        "                    total_files += 1\n",
        "\n",
        "        return total_files\n",
        "\n",
        "    train_total = copy_patient_files(train_patients, cfg.data.original_images_dir, cfg.data.original_labels_dir,\n",
        "                                   train_images_dir, train_labels_dir)\n",
        "\n",
        "    test_total = copy_patient_files(test_patients, cfg.data.original_images_dir, cfg.data.original_labels_dir,\n",
        "                                  test_images_dir, test_labels_dir)\n",
        "\n",
        "    return {\n",
        "        'train_images': train_images_dir,\n",
        "        'train_labels': train_labels_dir,\n",
        "        'test_images': test_images_dir,\n",
        "        'test_labels': test_labels_dir,\n",
        "        'train_patients': train_patients,\n",
        "        'test_patients': test_patients\n",
        "    }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T07:29:38.174796Z",
          "iopub.execute_input": "2025-11-15T07:29:38.175296Z",
          "iopub.status.idle": "2025-11-15T07:29:38.187116Z",
          "shell.execute_reply.started": "2025-11-15T07:29:38.175273Z",
          "shell.execute_reply": "2025-11-15T07:29:38.186273Z"
        },
        "id": "zNBbqzptObnZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Датасет"
      ],
      "metadata": {
        "id": "ohC3O2TgJoZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, images_dir, labels_dir, transform=None):\n",
        "        self.images_dir = images_dir\n",
        "        self.labels_dir = labels_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.image_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.png')])\n",
        "        self.label_files = sorted([f for f in os.listdir(labels_dir) if f.endswith('.png')])\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.images_dir, self.image_files[idx])\n",
        "        label_path = os.path.join(self.labels_dir, self.label_files[idx])\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image, mask=label)\n",
        "            image = transformed['image']\n",
        "            label = transformed['mask']\n",
        "        label = (label > 0).long()\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T07:29:38.188095Z",
          "iopub.execute_input": "2025-11-15T07:29:38.188463Z",
          "iopub.status.idle": "2025-11-15T07:29:38.256584Z",
          "shell.execute_reply.started": "2025-11-15T07:29:38.188439Z",
          "shell.execute_reply": "2025-11-15T07:29:38.255572Z"
        },
        "id": "yycXtF2gObnZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель Unet"
      ],
      "metadata": {
        "id": "8NpnAj2lJw2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n",
        "        block = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(out_channels),\n",
        "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(out_channels),\n",
        "        )\n",
        "        return block\n",
        "\n",
        "    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
        "        block = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(mid_channel),\n",
        "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(mid_channel),\n",
        "            torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=2, stride=2)\n",
        "        )\n",
        "        return block\n",
        "\n",
        "    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
        "        block = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(mid_channel),\n",
        "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(mid_channel),\n",
        "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n",
        "        )\n",
        "        return block\n",
        "\n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        super(UNet, self).__init__()\n",
        "        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\n",
        "        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv_encode2 = self.contracting_block(64, 128)\n",
        "        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv_encode3 = self.contracting_block(128, 256)\n",
        "        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.bottleneck = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(kernel_size=3, in_channels=256, out_channels=512, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            torch.nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.conv_decode3 = self.expansive_block(512, 256, 128)\n",
        "        self.conv_decode2 = self.expansive_block(256, 128, 64)\n",
        "        self.final_layer = self.final_block(128, 64, out_channel)\n",
        "\n",
        "    def crop_and_concat(self, upsampled, bypass):\n",
        "        _, _, h_up, w_up = upsampled.size()\n",
        "        _, _, h_by, w_by = bypass.size()\n",
        "\n",
        "        crop_h = (h_by - h_up) // 2\n",
        "        crop_w = (w_by - w_up) // 2\n",
        "\n",
        "        bypass_cropped = bypass[:, :,\n",
        "                              crop_h:crop_h + h_up,\n",
        "                              crop_w:crop_w + w_up]\n",
        "\n",
        "        return torch.cat((upsampled, bypass_cropped), 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encode_block1 = self.conv_encode1(x)\n",
        "        encode_pool1 = self.conv_maxpool1(encode_block1)\n",
        "\n",
        "        encode_block2 = self.conv_encode2(encode_pool1)\n",
        "        encode_pool2 = self.conv_maxpool2(encode_block2)\n",
        "\n",
        "        encode_block3 = self.conv_encode3(encode_pool2)\n",
        "        encode_pool3 = self.conv_maxpool3(encode_block3)\n",
        "\n",
        "        bottleneck1 = self.bottleneck(encode_pool3)\n",
        "\n",
        "        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3)\n",
        "        cat_layer2 = self.conv_decode3(decode_block3)\n",
        "\n",
        "        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2)\n",
        "        cat_layer1 = self.conv_decode2(decode_block2)\n",
        "\n",
        "        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1)\n",
        "        final_layer = self.final_layer(decode_block1)\n",
        "\n",
        "        return final_layer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T07:29:38.257612Z",
          "iopub.execute_input": "2025-11-15T07:29:38.257905Z",
          "iopub.status.idle": "2025-11-15T07:29:38.280443Z",
          "shell.execute_reply.started": "2025-11-15T07:29:38.257873Z",
          "shell.execute_reply": "2025-11-15T07:29:38.279547Z"
        },
        "id": "U7O5qetOObna"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Аугментация и предподготовка"
      ],
      "metadata": {
        "id": "g5YUhSiGJ0tL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "\n",
        "def transformers():\n",
        "    cfg = load_hydra_config()\n",
        "    train_transform = A.Compose([\n",
        "        A.Resize(height=cfg.transforms.image_size, width=cfg.transforms.image_size),\n",
        "\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.3),\n",
        "        A.RandomRotate90(p=0.5),\n",
        "        A.ShiftScaleRotate(\n",
        "            shift_limit=0.05,\n",
        "            scale_limit=0.1,\n",
        "            rotate_limit=10,\n",
        "            p=0.5\n",
        "        ),\n",
        "        A.RandomBrightnessContrast(\n",
        "            brightness_limit=0.1,\n",
        "            contrast_limit=0.1,\n",
        "            p=0.3\n",
        "        ),\n",
        "        A.GaussNoise(var_limit=(10.0, 30.0), mean=0, p=0.2),\n",
        "\n",
        "        A.Normalize(mean=[0.5], std=[0.5]),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "    val_transform = A.Compose([\n",
        "        A.Resize(height=cfg.transforms.image_size, width=cfg.transforms.image_size),\n",
        "        A.Normalize(mean=[0.5], std=[0.5]),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "    return train_transform, val_transform"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T07:29:38.283090Z",
          "iopub.execute_input": "2025-11-15T07:29:38.283404Z",
          "iopub.status.idle": "2025-11-15T07:29:39.509192Z",
          "shell.execute_reply.started": "2025-11-15T07:29:38.283347Z",
          "shell.execute_reply": "2025-11-15T07:29:39.508032Z"
        },
        "id": "oaDmNuPsObna"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_score_ce(predictions, targets, smooth=1e-6):\n",
        "    probs = torch.softmax(predictions, dim=1)\n",
        "\n",
        "    pred_probs = probs[:, 1]\n",
        "\n",
        "    pred_binary = torch.argmax(probs, dim=1)\n",
        "\n",
        "    pred_flat = pred_binary.flatten(1)\n",
        "    target_flat = targets.flatten(1)\n",
        "    intersection = (pred_flat * target_flat).sum(1)\n",
        "    union = pred_flat.sum(1) + target_flat.sum(1)\n",
        "\n",
        "    dice = (2. * intersection + smooth) / (union + smooth)\n",
        "\n",
        "    return dice.mean()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T07:30:15.300925Z",
          "iopub.execute_input": "2025-11-15T07:30:15.301274Z",
          "iopub.status.idle": "2025-11-15T07:30:15.317891Z",
          "shell.execute_reply.started": "2025-11-15T07:30:15.301243Z",
          "shell.execute_reply": "2025-11-15T07:30:15.316780Z"
        },
        "id": "gOqHBIHpObnb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n",
        "from torchmetrics import JaccardIndex\n",
        "\n",
        "from torchmetrics.segmentation import DiceScore\n",
        "\n",
        "from torchmetrics.classification import BinaryPrecision, BinaryRecall, BinaryF1Score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiuvASFAgnXF",
        "outputId": "dbc86f82-1def-466f-d040-9580ac6e259e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iou_metric = JaccardIndex(task='binary')  # или task='multiclass', num_classes=2\n",
        "dice_metric = DiceScore(num_classes=2, average='micro', input_format='index')\n",
        "precision_metric = BinaryPrecision()\n",
        "recall_metric = BinaryRecall()\n",
        "f1_metric = BinaryF1Score()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m60AWWZsojRT",
        "outputId": "99b50432-dcd6-4660-d5d2-779bd9b01472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: DiceScore metric currently defaults to `average=micro`, but will change to`average=macro` in the v1.9 release. If you've explicitly set this parameter, you can ignore this warning.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model():\n",
        "    cfg = load_hydra_config()\n",
        "    task = Task.init(\n",
        "        project_name=\"MedicalSegmentation\",\n",
        "        task_name=f\"UNet_{cfg.training.epochs}epochs\",\n",
        "        auto_connect_frameworks={'pytorch': True, 'hydra': True}\n",
        "    )\n",
        "    cfg_dict = OmegaConf.to_container(cfg, resolve=True)\n",
        "    task.connect_configuration(cfg_dict)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    paths = create_train_test_split_by_patient()\n",
        "    train_transform, val_transform = transformers()\n",
        "    train_dataset = SegmentationDataset(\n",
        "        images_dir=paths['train_images'],\n",
        "        labels_dir=paths['train_labels'],\n",
        "        transform=train_transform\n",
        "    )\n",
        "\n",
        "    test_dataset = SegmentationDataset(\n",
        "        images_dir=paths['test_images'],\n",
        "        labels_dir=paths['test_labels'],\n",
        "        transform=val_transform\n",
        "    )\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=cfg.training.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=cfg.data.num_workers\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=cfg.training.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=cfg.data.num_workers\n",
        "    )\n",
        "\n",
        "    model = UNet(cfg.model.in_channel, cfg.model.out_channel).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=cfg.training.learning_rate,\n",
        "        weight_decay=cfg.training.weight_decay\n",
        "    )\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                          mode='min')\n",
        "    train_losses = []\n",
        "    val_dice_scores = []\n",
        "    for epoch in range(cfg.training.epochs):\n",
        "        model.train()\n",
        "        epoch_train_loss = 0\n",
        "        train_pbar = tqdm(train_loader,desc=f'Epoch {epoch}/{cfg.training.epochs} [Train]')\n",
        "        for idx, (images, labels) in enumerate(train_pbar):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            labels = labels.long()\n",
        "            optimizer.zero_grad()\n",
        "            output = model(images)\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            epoch_train_loss += loss.item()\n",
        "\n",
        "            train_pbar.set_postfix({\n",
        "                'Loss': f'{loss.item():.4f}',\n",
        "                'Avg Loss': f'{epoch_train_loss/(idx+1):.4f}'\n",
        "            })\n",
        "        train_pbar.close()\n",
        "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
        "        model.eval()\n",
        "        epoch_val_dice = 0\n",
        "        val_batches = 0\n",
        "        val_pbar = tqdm(test_loader, desc=f'Epoch {epoch+1}/{cfg.training.epochs} [Val]')\n",
        "        with torch.no_grad():\n",
        "            for idx, (images, masks) in enumerate(val_pbar):\n",
        "                images, masks = images.to(device), masks.to(device)\n",
        "                masks = masks.long()\n",
        "\n",
        "                outputs = model(images)\n",
        "                probs = torch.softmax(outputs, dim=1)\n",
        "                preds = torch.argmax(probs, dim=1)\n",
        "                masks = masks.long()\n",
        "                masks = masks.unsqueeze(1)\n",
        "                preds = preds.squeeze(1)\n",
        "                dice_metric.update(outputs, masks)\n",
        "\n",
        "                val_batches += 1\n",
        "                val_pbar.set_postfix({\n",
        "                    'Dice': f'{dice_metric.item():.4f}',\n",
        "                    'Avg Dice': f'{epoch_val_dice/(idx+1):.4f}'\n",
        "                })\n",
        "\n",
        "        val_pbar.close()\n",
        "\n",
        "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
        "        avg_val_dice = dice_metric.compute()\n",
        "        logger = Logger.current_logger()\n",
        "        logger.report_scalar(\"Loss\", \"Train\", avg_train_loss, epoch)\n",
        "        logger.report_scalar(\"Metrics\", \"Dice\", avg_val_dice, epoch)\n",
        "        train_losses.append(avg_train_loss)\n",
        "        val_dice_scores.append(avg_val_dice)\n",
        "        scheduler.step(avg_train_loss)\n",
        "        print(f'Epoch {epoch:03d}:')\n",
        "        print(f'  Loss: {avg_train_loss:.4f}')\n",
        "        print(f'  Dice: {avg_val_dice:.4f}')\n",
        "        print(f'  LR:   {optimizer.param_groups[0][\"lr\"]:.2e}')\n",
        "        print('-' * 40)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T07:30:15.318893Z",
          "iopub.execute_input": "2025-11-15T07:30:15.319193Z",
          "iopub.status.idle": "2025-11-15T07:30:15.339812Z",
          "shell.execute_reply.started": "2025-11-15T07:30:15.319169Z",
          "shell.execute_reply": "2025-11-15T07:30:15.338997Z"
        },
        "id": "subI8KbrObnb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    results = train_model()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T07:30:15.340811Z",
          "iopub.execute_input": "2025-11-15T07:30:15.341141Z",
          "execution_failed": "2025-11-15T10:47:36.006Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o6KyklqObnb",
        "outputId": "95427098-2251-45f9-8fe7-d20709b9a3cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning:\n",
            "\n",
            "ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "\n",
            "/tmp/ipython-input-2562268279.py:24: UserWarning:\n",
            "\n",
            "Argument(s) 'var_limit, mean' are not valid for transform GaussNoise\n",
            "\n",
            "Epoch 0/40 [Train]:  92%|█████████▏| 229/250 [02:56<00:15,  1.33it/s, Loss=0.0937, Avg Loss=0.3684]"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RzKrez9wtmoa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}