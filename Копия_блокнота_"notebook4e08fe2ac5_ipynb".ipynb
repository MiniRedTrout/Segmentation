{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 13734718,
          "sourceType": "datasetVersion",
          "datasetId": 8738907
        }
      ],
      "dockerImageVersionId": 31192,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiniRedTrout/Segmentation/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22notebook4e08fe2ac5_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импорт библиотек"
      ],
      "metadata": {
        "id": "KfVqj6hhJWaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T07:29:31.131600Z",
          "iopub.execute_input": "2025-11-15T07:29:31.131962Z",
          "iopub.status.idle": "2025-11-15T07:29:38.173868Z",
          "shell.execute_reply.started": "2025-11-15T07:29:31.131926Z",
          "shell.execute_reply": "2025-11-15T07:29:38.173001Z"
        },
        "id": "AbrPBBBBObnY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Путь датасета с kaggle"
      ],
      "metadata": {
        "id": "G9XJZ0byJaYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"miniredtrout/abdominalaorta\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1y9iTbfQQXr",
        "outputId": "cc6cda22-c6c0-476a-de21-d4acc88663ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'abdominalaorta' dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "35HxSbGIRI_2",
        "outputId": "2f8176ff-9c6f-4e70-a34a-554a295d4977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/kaggle/input/abdominalaorta'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hydra-core omegaconf\n",
        "import hydra\n",
        "from omegaconf import DictConfig, OmegaConf\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dnAHsMaOtm5",
        "outputId": "1559eb2b-c70a-4369-e379-008676b2ff90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from hydra-core) (25.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf) (6.0.3)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hydra-core\n",
            "Successfully installed hydra-core-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install clearml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOzioQ7gdfYq",
        "outputId": "7223695f-4963-418a-c384-fa3f2495701d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting clearml\n",
            "  Downloading clearml-2.0.2-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: attrs>=18.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (25.4.0)\n",
            "Collecting furl>=2.0.0 (from clearml)\n",
            "  Downloading furl-2.1.4-py2.py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (4.25.1)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.0.2)\n",
            "Collecting pathlib2>=2.3.0 (from clearml)\n",
            "  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: psutil>=3.4.2 in /usr/local/lib/python3.12/dist-packages (from clearml) (5.9.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from clearml) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.9.0.post0)\n",
            "Requirement already satisfied: pyjwt<2.11.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.10.1)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.12/dist-packages (from clearml) (6.0.3)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.5.0)\n",
            "Requirement already satisfied: Pillow>=10.3.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (11.3.0)\n",
            "Requirement already satisfied: referencing<0.40 in /usr/local/lib/python3.12/dist-packages (from clearml) (0.37.0)\n",
            "Requirement already satisfied: requests>=2.32.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.32.4)\n",
            "Collecting orderedmultidict>=1.0.1 (from furl>=2.0.0->clearml)\n",
            "  Downloading orderedmultidict-1.0.2-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6.0->clearml) (2025.9.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6.0->clearml) (0.28.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing<0.40->clearml) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.0->clearml) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.0->clearml) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.0->clearml) (2025.10.5)\n",
            "Downloading clearml-2.0.2-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading furl-2.1.4-py2.py3-none-any.whl (27 kB)\n",
            "Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\n",
            "Downloading orderedmultidict-1.0.2-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pathlib2, orderedmultidict, furl, clearml\n",
            "Successfully installed clearml-2.0.2 furl-2.1.4 orderedmultidict-1.0.2 pathlib2-2.3.7.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
        "%env CLEARML_API_HOST=https://api.clear.ml\n",
        "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
        "%env CLEARML_API_ACCESS_KEY=XGMS61QRIXH7G4URU0X7VGTDAIQUVE\n",
        "%env CLEARML_API_SECRET_KEY=3mpOB_Br37BLBntBoUvtxmfbBfmkbkdfRUYGje8GfL1gwe_ufJd1w4UzuQWOPaAtTWE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUj8P68pvOai",
        "outputId": "e36d97c0-e128-4617-d1af-aaa81442e258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CLEARML_WEB_HOST=https://app.clear.ml/\n",
            "env: CLEARML_API_HOST=https://api.clear.ml\n",
            "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
            "env: CLEARML_API_ACCESS_KEY=XGMS61QRIXH7G4URU0X7VGTDAIQUVE\n",
            "env: CLEARML_API_SECRET_KEY=3mpOB_Br37BLBntBoUvtxmfbBfmkbkdfRUYGje8GfL1gwe_ufJd1w4UzuQWOPaAtTWE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from clearml import Task, Logger"
      ],
      "metadata": {
        "id": "6_SELnD-dYv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import hydra\n",
        "from omegaconf import DictConfig, OmegaConf\n",
        "\n",
        "config_dir = '/content/drive/MyDrive/segmentation_project/config'\n",
        "import shutil\n",
        "if os.path.exists(config_dir):\n",
        "    shutil.rmtree(config_dir)\n",
        "\n",
        "os.makedirs(config_dir, exist_ok=True)\n",
        "\n",
        "simple_config = \"\"\"\n",
        "training:\n",
        "  batch_size: 16\n",
        "  epochs: 40\n",
        "  learning_rate: 0.0002\n",
        "  optimizer: \"AdamW\"\n",
        "  weight_decay: 0.01\n",
        "\n",
        "data:\n",
        "  original_images_dir: \"/kaggle/input/abdominalaorta/images\"\n",
        "  original_labels_dir: \"/kaggle/input/abdominalaorta/labels\"\n",
        "  output_base_dir: \"/content/base_patients\"\n",
        "  test_size: 0.2\n",
        "  random_state: 42\n",
        "  image_size: 256\n",
        "  num_workers: 4\n",
        "\n",
        "model:\n",
        "  in_channel: 1\n",
        "  out_channel: 2\n",
        "\n",
        "transforms:\n",
        "  image_size: 256\n",
        "  augmentation:\n",
        "    horizontal_flip_p: 0.5\n",
        "    vertical_flip_p: 0.3\n",
        "    rotate90_p: 0.5\n",
        "    affine_p: 0.5\n",
        "    brightness_contrast_p: 0.3\n",
        "    noise_p: 0.2\n",
        "\"\"\"\n",
        "\n",
        "with open(f'{config_dir}/config.yaml', 'w') as f:\n",
        "    f.write(simple_config)\n",
        "\n",
        "def load_hydra_config():\n",
        "    config_path = \"/content/drive/MyDrive/segmentation_project/config\"\n",
        "    config_name = \"config\"\n",
        "\n",
        "    with hydra.initialize_config_dir(config_dir=config_path, version_base=\"1.2\"):\n",
        "        cfg = hydra.compose(config_name=config_name)\n",
        "\n",
        "    OmegaConf.set_struct(cfg, False)\n",
        "\n",
        "    return cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3J-8nzvrbqu",
        "outputId": "d7e753cc-30e3-4cfe-ac2f-ee270dc2230b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Простой конфиг создан!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разделение на train test выборку по пациентам"
      ],
      "metadata": {
        "id": "DxpjPceMJe3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_test_split_by_patient():\n",
        "    cfg = load_hydra_config()\n",
        "    patient_folders = []\n",
        "    for folder in os.listdir(cfg.data.original_images_dir):\n",
        "        folder_path = os.path.join(cfg.data.original_images_dir, folder)\n",
        "        if (os.path.isdir(folder_path) and\n",
        "            os.path.exists(os.path.join(cfg.data.original_labels_dir, folder))):\n",
        "            patient_folders.append(folder)\n",
        "\n",
        "    train_patients, test_patients = train_test_split(\n",
        "        patient_folders,\n",
        "        test_size=cfg.data.test_size,\n",
        "        random_state=cfg.data.random_state\n",
        "    )\n",
        "\n",
        "    train_images_dir = os.path.join(cfg.data.output_base_dir, 'train', 'images')\n",
        "    train_labels_dir = os.path.join(cfg.data.output_base_dir, 'train', 'labels')\n",
        "    test_images_dir = os.path.join(cfg.data.output_base_dir, 'test', 'images')\n",
        "    test_labels_dir = os.path.join(cfg.data.output_base_dir, 'test', 'labels')\n",
        "\n",
        "    for dir_path in [train_images_dir, train_labels_dir, test_images_dir, test_labels_dir]:\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "    def copy_patient_files(patients, src_images_dir, src_labels_dir, dst_images_dir, dst_labels_dir):\n",
        "        total_files = 0\n",
        "        for patient in patients:\n",
        "            patient_images_dir = os.path.join(src_images_dir, patient)\n",
        "            patient_labels_dir = os.path.join(src_labels_dir, patient)\n",
        "\n",
        "            for file in os.listdir(patient_images_dir):\n",
        "                if file.endswith('.png'):\n",
        "                    src_image_path = os.path.join(patient_images_dir, file)\n",
        "                    dst_image_path = os.path.join(dst_images_dir, f\"{patient}_{file}\")\n",
        "                    shutil.copy2(src_image_path, dst_image_path)\n",
        "\n",
        "                    src_label_path = os.path.join(patient_labels_dir, file)\n",
        "                    dst_label_path = os.path.join(dst_labels_dir, f\"{patient}_{file}\")\n",
        "                    shutil.copy2(src_label_path, dst_label_path)\n",
        "\n",
        "                    total_files += 1\n",
        "\n",
        "        return total_files\n",
        "\n",
        "    train_total = copy_patient_files(train_patients, cfg.data.original_images_dir, cfg.data.original_labels_dir,\n",
        "                                   train_images_dir, train_labels_dir)\n",
        "\n",
        "    test_total = copy_patient_files(test_patients, cfg.data.original_images_dir, cfg.data.original_labels_dir,\n",
        "                                  test_images_dir, test_labels_dir)\n",
        "\n",
        "    return {\n",
        "        'train_images': train_images_dir,\n",
        "        'train_labels': train_labels_dir,\n",
        "        'test_images': test_images_dir,\n",
        "        'test_labels': test_labels_dir,\n",
        "        'train_patients': train_patients,\n",
        "        'test_patients': test_patients\n",
        "    }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T07:29:38.174796Z",
          "iopub.execute_input": "2025-11-15T07:29:38.175296Z",
          "iopub.status.idle": "2025-11-15T07:29:38.187116Z",
          "shell.execute_reply.started": "2025-11-15T07:29:38.175273Z",
          "shell.execute_reply": "2025-11-15T07:29:38.186273Z"
        },
        "id": "zNBbqzptObnZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Датасет"
      ],
      "metadata": {
        "id": "ohC3O2TgJoZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, images_dir, labels_dir, transform=None):\n",
        "        self.images_dir = images_dir\n",
        "        self.labels_dir = labels_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.image_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.png')])\n",
        "        self.label_files = sorted([f for f in os.listdir(labels_dir) if f.endswith('.png')])\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.images_dir, self.image_files[idx])\n",
        "        label_path = os.path.join(self.labels_dir, self.label_files[idx])\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image, mask=label)\n",
        "            image = transformed['image']\n",
        "            label = transformed['mask']\n",
        "        label = (label > 0).long()\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T07:29:38.188095Z",
          "iopub.execute_input": "2025-11-15T07:29:38.188463Z",
          "iopub.status.idle": "2025-11-15T07:29:38.256584Z",
          "shell.execute_reply.started": "2025-11-15T07:29:38.188439Z",
          "shell.execute_reply": "2025-11-15T07:29:38.255572Z"
        },
        "id": "yycXtF2gObnZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель Unet"
      ],
      "metadata": {
        "id": "8NpnAj2lJw2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n",
        "        block = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(out_channels),\n",
        "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(out_channels),\n",
        "        )\n",
        "        return block\n",
        "\n",
        "    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
        "        block = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(mid_channel),\n",
        "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(mid_channel),\n",
        "            torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=2, stride=2)\n",
        "        )\n",
        "        return block\n",
        "\n",
        "    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
        "        block = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(mid_channel),\n",
        "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(mid_channel),\n",
        "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n",
        "        )\n",
        "        return block\n",
        "\n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        super(UNet, self).__init__()\n",
        "        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\n",
        "        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv_encode2 = self.contracting_block(64, 128)\n",
        "        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv_encode3 = self.contracting_block(128, 256)\n",
        "        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.bottleneck = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(kernel_size=3, in_channels=256, out_channels=512, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            torch.nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.conv_decode3 = self.expansive_block(512, 256, 128)\n",
        "        self.conv_decode2 = self.expansive_block(256, 128, 64)\n",
        "        self.final_layer = self.final_block(128, 64, out_channel)\n",
        "\n",
        "    def crop_and_concat(self, upsampled, bypass):\n",
        "        _, _, h_up, w_up = upsampled.size()\n",
        "        _, _, h_by, w_by = bypass.size()\n",
        "\n",
        "        crop_h = (h_by - h_up) // 2\n",
        "        crop_w = (w_by - w_up) // 2\n",
        "\n",
        "        bypass_cropped = bypass[:, :,\n",
        "                              crop_h:crop_h + h_up,\n",
        "                              crop_w:crop_w + w_up]\n",
        "\n",
        "        return torch.cat((upsampled, bypass_cropped), 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encode_block1 = self.conv_encode1(x)\n",
        "        encode_pool1 = self.conv_maxpool1(encode_block1)\n",
        "\n",
        "        encode_block2 = self.conv_encode2(encode_pool1)\n",
        "        encode_pool2 = self.conv_maxpool2(encode_block2)\n",
        "\n",
        "        encode_block3 = self.conv_encode3(encode_pool2)\n",
        "        encode_pool3 = self.conv_maxpool3(encode_block3)\n",
        "\n",
        "        bottleneck1 = self.bottleneck(encode_pool3)\n",
        "\n",
        "        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3)\n",
        "        cat_layer2 = self.conv_decode3(decode_block3)\n",
        "\n",
        "        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2)\n",
        "        cat_layer1 = self.conv_decode2(decode_block2)\n",
        "\n",
        "        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1)\n",
        "        final_layer = self.final_layer(decode_block1)\n",
        "\n",
        "        return final_layer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T07:29:38.257612Z",
          "iopub.execute_input": "2025-11-15T07:29:38.257905Z",
          "iopub.status.idle": "2025-11-15T07:29:38.280443Z",
          "shell.execute_reply.started": "2025-11-15T07:29:38.257873Z",
          "shell.execute_reply": "2025-11-15T07:29:38.279547Z"
        },
        "id": "U7O5qetOObna"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Аугментация и предподготовка"
      ],
      "metadata": {
        "id": "g5YUhSiGJ0tL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "\n",
        "def transformers():\n",
        "    cfg = load_hydra_config()\n",
        "    train_transform = A.Compose([\n",
        "        A.Resize(height=cfg.transforms.image_size, width=cfg.transforms.image_size),\n",
        "\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.3),\n",
        "        A.RandomRotate90(p=0.5),\n",
        "        A.Affine(\n",
        "            translate_percent={'x': (-0.05, 0.05), 'y': (-0.05, 0.05)},\n",
        "            scale=(0.9, 1.1),\n",
        "            rotate=(-10, 10),\n",
        "            p=0.5\n",
        "        ),\n",
        "        A.RandomBrightnessContrast(\n",
        "            brightness_limit=0.1,\n",
        "            contrast_limit=0.1,\n",
        "            p=0.3\n",
        "        ),\n",
        "        A.GaussNoise(var_limit=(10.0, 30.0), p=0.2),\n",
        "\n",
        "        A.Normalize(mean=[0.5], std=[0.5]),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "    val_transform = A.Compose([\n",
        "        A.Resize(height=cfg.transforms.image_size, width=cfg.transforms.image_size),\n",
        "        A.Normalize(mean=[0.5], std=[0.5]),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "    return train_transform, val_transform"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T07:29:38.283090Z",
          "iopub.execute_input": "2025-11-15T07:29:38.283404Z",
          "iopub.status.idle": "2025-11-15T07:29:39.509192Z",
          "shell.execute_reply.started": "2025-11-15T07:29:38.283347Z",
          "shell.execute_reply": "2025-11-15T07:29:39.508032Z"
        },
        "id": "oaDmNuPsObna"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n",
        "from torchmetrics.segmentation import DiceScore\n",
        "from torchmetrics import JaccardIndex\n",
        "from torchmetrics import Precision, Recall\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiuvASFAgnXF",
        "outputId": "9c530985-f39f-47ba-b4a4-882021e37610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model():\n",
        "    cfg = load_hydra_config()\n",
        "    task = Task.init(\n",
        "        project_name=\"MedicalSegmentation\",\n",
        "        task_name=f\"UNet_{cfg.training.epochs}epochs\",\n",
        "        auto_connect_frameworks={'pytorch': True, 'hydra': True}\n",
        "    )\n",
        "    cfg_dict = OmegaConf.to_container(cfg, resolve=True)\n",
        "    task.connect_configuration(cfg_dict)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    paths = create_train_test_split_by_patient()\n",
        "    train_transform, val_transform = transformers()\n",
        "    train_dataset = SegmentationDataset(\n",
        "        images_dir=paths['train_images'],\n",
        "        labels_dir=paths['train_labels'],\n",
        "        transform=train_transform\n",
        "    )\n",
        "\n",
        "    test_dataset = SegmentationDataset(\n",
        "        images_dir=paths['test_images'],\n",
        "        labels_dir=paths['test_labels'],\n",
        "        transform=val_transform\n",
        "    )\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=cfg.training.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=cfg.data.num_workers\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=cfg.training.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=cfg.data.num_workers\n",
        "    )\n",
        "\n",
        "    model = UNet(cfg.model.in_channel, cfg.model.out_channel).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=cfg.training.learning_rate,\n",
        "        weight_decay=cfg.training.weight_decay\n",
        "    )\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
        "    dice_metric = DiceScore(num_classes=2, average='macro', input_format='index').to(device)\n",
        "    iou_metric = JaccardIndex(num_classes=2, task='multiclass', average='macro').to(device)\n",
        "    precision_metric = Precision(num_classes=2, task='multiclass',average='macro').to(device)\n",
        "    recall_metric = Recall(num_classes=2, task='multiclass',average='macro').to(device)\n",
        "\n",
        "    train_losses = []\n",
        "    val_dice_scores = []\n",
        "    val_iou_scores = []\n",
        "    val_pres_scores = []\n",
        "    val_rec_scores = []\n",
        "    best_dice = 0\n",
        "    best_epoch = 0\n",
        "    for epoch in range(cfg.training.epochs):\n",
        "        model.train()\n",
        "        epoch_train_loss = 0\n",
        "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch}/{cfg.training.epochs} [Train]')\n",
        "\n",
        "        for idx, (images, labels) in enumerate(train_pbar):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            labels = labels.long()\n",
        "            optimizer.zero_grad()\n",
        "            output = model(images)\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            epoch_train_loss += loss.item()\n",
        "\n",
        "            train_pbar.set_postfix({\n",
        "                'Loss': f'{loss.item():.4f}',\n",
        "                'Avg Loss': f'{epoch_train_loss/(idx+1):.4f}'\n",
        "            })\n",
        "\n",
        "        train_pbar.close()\n",
        "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        epoch_val_dice = 0\n",
        "        val_batches = 0\n",
        "        val_pbar = tqdm(test_loader, desc=f'Epoch {epoch+1}/{cfg.training.epochs} [Val]')\n",
        "\n",
        "\n",
        "        dice_metric.reset()\n",
        "        iou_metric.reset()\n",
        "        precision_metric.reset()\n",
        "        recall_metric.reset()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for idx, (images, masks) in enumerate(val_pbar):\n",
        "                images, masks = images.to(device), masks.to(device)\n",
        "                masks = masks.long()\n",
        "                outputs = model(images)\n",
        "                probs = torch.softmax(outputs, dim=1)\n",
        "                preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "                dice_metric.update(preds, masks)\n",
        "                iou_metric.update(preds, masks)\n",
        "                precision_metric.update(preds, masks)\n",
        "                recall_metric.update(preds, masks)\n",
        "\n",
        "                val_batches += 1\n",
        "\n",
        "                val_pbar.set_postfix({\n",
        "                    'Avg Dice': f'{epoch_val_dice/val_batches:.4f}'\n",
        "                })\n",
        "\n",
        "        val_pbar.close()\n",
        "        avg_val_dice = dice_metric.compute()\n",
        "        avg_val_iou = iou_metric.compute()\n",
        "        avg_val_pres = precision_metric.compute()\n",
        "        avg_val_rec = recall_metric.compute()\n",
        "        if avg_val_dice > best_dice:\n",
        "            best_dice = avg_val_dice.item()\n",
        "            best_epoch = epoch\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'dice_score': best_dice,\n",
        "                'iou_score': avg_val_iou.item(),\n",
        "                'loss': avg_train_loss,\n",
        "            }, 'best_model.pth')\n",
        "\n",
        "        logger = Logger.current_logger()\n",
        "        logger.report_scalar(\"Loss\", \"Train\", avg_train_loss, epoch)\n",
        "        logger.report_scalar(\"Metrics\", \"Dice\", avg_val_dice.item(), epoch)\n",
        "        logger.report_scalar(\"Metrics\", \"Iou\", avg_val_iou.item(), epoch)\n",
        "        logger.report_scalar(\"Metrics\", \"Precision\", avg_val_pres.item(), epoch)\n",
        "        logger.report_scalar(\"Metrics\", \"Recall\", avg_val_rec.item(), epoch)\n",
        "\n",
        "        train_losses.append(avg_train_loss)\n",
        "        val_dice_scores.append(avg_val_dice.item())\n",
        "        val_iou_scores.append(avg_val_iou.item())\n",
        "        val_pres_scores.append(avg_val_pres.item())\n",
        "        val_rec_scores.append(avg_val_rec.item())\n",
        "\n",
        "        scheduler.step(avg_train_loss)\n",
        "\n",
        "        print(f'Epoch {epoch:03d}:')\n",
        "        print(f'  Loss: {avg_train_loss:.4f}')\n",
        "        print(f'  Dice: {avg_val_dice.item():.4f}')\n",
        "        print(f'  Iou: {avg_val_iou.item():.4f}')\n",
        "        print(f'  Precision: {avg_val_pres.item():.4f}')\n",
        "        print(f'  Recall: {avg_val_rec.item():.4f}')\n",
        "        print(f'  LR:   {optimizer.param_groups[0][\"lr\"]:.2e}')\n",
        "        print(f'Best Dice {best_dice:.4f} Epoch {best_epoch}')\n",
        "        print('-' * 40)"
      ],
      "metadata": {
        "id": "cwiGIXNmu0Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    results = train_model()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T07:30:15.340811Z",
          "iopub.execute_input": "2025-11-15T07:30:15.341141Z",
          "execution_failed": "2025-11-15T10:47:36.006Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o6KyklqObnb",
        "outputId": "6beb542d-39d2-416b-e35c-dad591733c8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-624610810.py:24: UserWarning:\n",
            "\n",
            "Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
            "\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning:\n",
            "\n",
            "This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n",
            "Epoch 0/40 [Train]:   2%|▏         | 7/350 [00:06<04:35,  1.25it/s, Loss=0.7066, Avg Loss=0.7339]"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MiniRedTrout/Segmentation.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBOyGlioVOvw",
        "outputId": "b195c4dd-efcd-47d5-a68f-229dab682d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Segmentation'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 9 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (9/9), 8.75 MiB | 9.47 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7KHRK25WHVu",
        "outputId": "92d52da6-94dd-484a-e19d-0d68e35c6910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Segmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ColabNotebooks/notebook4e08fe2ac5.ipynb /content/Segmentation/notebook4e08fe2ac5.ipynb"
      ],
      "metadata": {
        "id": "Pmt-vP6_XQLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"enemydoctor@gmail.com\"\n",
        "!git config --global user.name \"MiniRedTrout\""
      ],
      "metadata": {
        "id": "xdrYXyFuXpYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRAiMXr3Yd9_",
        "outputId": "96248ad2-bcab-4942-bc0d-ca4cb0f8a684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   notebook4e08fe2ac5.ipynb\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mSegmentation/\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git diff notebook4e08fe2ac5.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4oJXlp1YfyV",
        "outputId": "118d4ab6-94b0-4e0d-b5e5-4070c1fa3bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mdiff --git a/notebook4e08fe2ac5.ipynb b/notebook4e08fe2ac5.ipynb\u001b[m\n",
            "\u001b[1mindex c70ff32..7a87544 100644\u001b[m\n",
            "\u001b[1m--- a/notebook4e08fe2ac5.ipynb\u001b[m\n",
            "\u001b[1m+++ b/notebook4e08fe2ac5.ipynb\u001b[m\n",
            "\u001b[36m@@ -1,979 +1 @@\u001b[m\n",
            "\u001b[31m-{\u001b[m\n",
            "\u001b[31m-  \"metadata\": {\u001b[m\n",
            "\u001b[31m-    \"kernelspec\": {\u001b[m\n",
            "\u001b[31m-      \"display_name\": \"Python 3\",\u001b[m\n",
            "\u001b[31m-      \"name\": \"python3\"\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    \"language_info\": {\u001b[m\n",
            "\u001b[31m-      \"name\": \"python\",\u001b[m\n",
            "\u001b[31m-      \"version\": \"3.11.13\",\u001b[m\n",
            "\u001b[31m-      \"mimetype\": \"text/x-python\",\u001b[m\n",
            "\u001b[31m-      \"codemirror_mode\": {\u001b[m\n",
            "\u001b[31m-        \"name\": \"ipython\",\u001b[m\n",
            "\u001b[31m-        \"version\": 3\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"pygments_lexer\": \"ipython3\",\u001b[m\n",
            "\u001b[31m-      \"nbconvert_exporter\": \"python\",\u001b[m\n",
            "\u001b[31m-      \"file_extension\": \".py\"\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    \"kaggle\": {\u001b[m\n",
            "\u001b[31m-      \"accelerator\": \"none\",\u001b[m\n",
            "\u001b[31m-      \"dataSources\": [\u001b[m\n",
            "\u001b[31m-        {\u001b[m\n",
            "\u001b[31m-          \"sourceId\": 13734718,\u001b[m\n",
            "\u001b[31m-          \"sourceType\": \"datasetVersion\",\u001b[m\n",
            "\u001b[31m-          \"datasetId\": 8738907\u001b[m\n",
            "\u001b[31m-        }\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"dockerImageVersionId\": 31192,\u001b[m\n",
            "\u001b[31m-      \"isInternetEnabled\": true,\u001b[m\n",
            "\u001b[31m-      \"language\": \"python\",\u001b[m\n",
            "\u001b[31m-      \"sourceType\": \"notebook\",\u001b[m\n",
            "\u001b[31m-      \"isGpuEnabled\": false\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    \"colab\": {\u001b[m\n",
            "\u001b[31m-      \"provenance\": [],\u001b[m\n",
            "\u001b[31m-      \"gpuType\": \"T4\",\u001b[m\n",
            "\u001b[31m-      \"include_colab_link\": true\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    \"accelerator\": \"GPU\"\u001b[m\n",
            "\u001b[31m-  },\u001b[m\n",
            "\u001b[31m-  \"nbformat_minor\": 0,\u001b[m\n",
            "\u001b[31m-  \"nbformat\": 4,\u001b[m\n",
            "\u001b[31m-  \"cells\": [\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"markdown\",\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"id\": \"view-in-github\",\u001b[m\n",
            "\u001b[31m-        \"colab_type\": \"text\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"<a href=\\\"https://colab.research.google.com/github/MiniRedTrout/Segmentation/blob/main/notebook4e08fe2ac5.ipynb\\\" target=\\\"_parent\\\"><img src=\\\"https://colab.research.google.com/assets/colab-badge.svg\\\" alt=\\\"Open In Colab\\\"/></a>\"\u001b[m\n",
            "\u001b[31m-      ]\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"markdown\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"Импорт библиотек\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"id\": \"KfVqj6hhJWaU\"\u001b[m\n",
            "\u001b[31m-      }\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"import torch\\n\",\u001b[m\n",
            "\u001b[31m-        \"from torch.utils.data import Dataset, DataLoader\\n\",\u001b[m\n",
            "\u001b[31m-        \"from PIL import Image\\n\",\u001b[m\n",
            "\u001b[31m-        \"import torchvision.transforms as transforms\\n\",\u001b[m\n",
            "\u001b[31m-        \"import numpy as np\\n\",\u001b[m\n",
            "\u001b[31m-        \"import pandas as pd\\n\",\u001b[m\n",
            "\u001b[31m-        \"import os\\n\",\u001b[m\n",
            "\u001b[31m-        \"import scipy.io\\n\",\u001b[m\n",
            "\u001b[31m-        \"import matplotlib.pyplot as plt\\n\",\u001b[m\n",
            "\u001b[31m-        \"from tqdm import tqdm\\n\",\u001b[m\n",
            "\u001b[31m-        \"import torch.nn as nn\\n\",\u001b[m\n",
            "\u001b[31m-        \"import torch.nn.functional as F\\n\",\u001b[m\n",
            "\u001b[31m-        \"from sklearn.model_selection import train_test_split\\n\",\u001b[m\n",
            "\u001b[31m-        \"import shutil\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"trusted\": true,\u001b[m\n",
            "\u001b[31m-        \"execution\": {\u001b[m\n",
            "\u001b[31m-          \"iopub.status.busy\": \"2025-11-15T07:29:31.131600Z\",\u001b[m\n",
            "\u001b[31m-          \"iopub.execute_input\": \"2025-11-15T07:29:31.131962Z\",\u001b[m\n",
            "\u001b[31m-          \"iopub.status.idle\": \"2025-11-15T07:29:38.173868Z\",\u001b[m\n",
            "\u001b[31m-          \"shell.execute_reply.started\": \"2025-11-15T07:29:31.131926Z\",\u001b[m\n",
            "\u001b[31m-          \"shell.execute_reply\": \"2025-11-15T07:29:38.173001Z\"\u001b[m\n",
            "\u001b[31m-        },\u001b[m\n",
            "\u001b[31m-        \"id\": \"AbrPBBBBObnY\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"outputs\": [],\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"markdown\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"Путь датасета с kaggle\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"id\": \"G9XJZ0byJaYR\"\u001b[m\n",
            "\u001b[31m-      }\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"import kagglehub\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"# Download latest version\\n\",\u001b[m\n",
            "\u001b[31m-        \"path = kagglehub.dataset_download(\\\"miniredtrout/abdominalaorta\\\")\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"colab\": {\u001b[m\n",
            "\u001b[31m-          \"base_uri\": \"https://localhost:8080/\"\u001b[m\n",
            "\u001b[31m-        },\u001b[m\n",
            "\u001b[31m-        \"id\": \"C1y9iTbfQQXr\",\u001b[m\n",
            "\u001b[31m-        \"outputId\": \"7824adc3-7f19-4f9a-9c76-a58ac5bda621\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null,\u001b[m\n",
            "\u001b[31m-      \"outputs\": [\u001b[m\n",
            "\u001b[31m-        {\u001b[m\n",
            "\u001b[31m-          \"output_type\": \"stream\",\u001b[m\n",
            "\u001b[31m-          \"name\": \"stdout\",\u001b[m\n",
            "\u001b[31m-          \"text\": [\u001b[m\n",
            "\u001b[31m-            \"Using Colab cache for faster access to the 'abdominalaorta' dataset.\\n\"\u001b[m\n",
            "\u001b[31m-          ]\u001b[m\n",
            "\u001b[31m-        }\u001b[m\n",
            "\u001b[31m-      ]\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"path\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"colab\": {\u001b[m\n",
            "\u001b[31m-          \"base_uri\": \"https://localhost:8080/\",\u001b[m\n",
            "\u001b[31m-          \"height\": 35\u001b[m\n",
            "\u001b[31m-        },\u001b[m\n",
            "\u001b[31m-        \"id\": \"35HxSbGIRI_2\",\u001b[m\n",
            "\u001b[31m-        \"outputId\": \"48eb4e6e-21a0-4cce-f5e7-e163655837b7\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null,\u001b[m\n",
            "\u001b[31m-      \"outputs\": [\u001b[m\n",
            "\u001b[31m-        {\u001b[m\n",
            "\u001b[31m-          \"output_type\": \"execute_result\",\u001b[m\n",
            "\u001b[31m-          \"data\": {\u001b[m\n",
            "\u001b[31m-            \"text/plain\": [\u001b[m\n",
            "\u001b[31m-              \"'/kaggle/input/abdominalaorta'\"\u001b[m\n",
            "\u001b[31m-            ],\u001b[m\n",
            "\u001b[31m-            \"application/vnd.google.colaboratory.intrinsic+json\": {\u001b[m\n",
            "\u001b[31m-              \"type\": \"string\"\u001b[m\n",
            "\u001b[31m-            }\u001b[m\n",
            "\u001b[31m-          },\u001b[m\n",
            "\u001b[31m-          \"metadata\": {},\u001b[m\n",
            "\u001b[31m-          \"execution_count\": 12\u001b[m\n",
            "\u001b[31m-        }\u001b[m\n",
            "\u001b[31m-      ]\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"!pip install hydra-core omegaconf\\n\",\u001b[m\n",
            "\u001b[31m-        \"import hydra\\n\",\u001b[m\n",
            "\u001b[31m-        \"from omegaconf import DictConfig, OmegaConf\\n\",\u001b[m\n",
            "\u001b[31m-        \"import os\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"colab\": {\u001b[m\n",
            "\u001b[31m-          \"base_uri\": \"https://localhost:8080/\"\u001b[m\n",
            "\u001b[31m-        },\u001b[m\n",
            "\u001b[31m-        \"id\": \"6dnAHsMaOtm5\",\u001b[m\n",
            "\u001b[31m-        \"outputId\": \"5773b30f-ee5d-48fc-ce59-edded26e5488\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null,\u001b[m\n",
            "\u001b[31m-      \"outputs\": [\u001b[m\n",
            "\u001b[31m-        {\u001b[m\n",
            "\u001b[31m-          \"output_type\": \"stream\",\u001b[m\n",
            "\u001b[31m-          \"name\": \"stdout\",\u001b[m\n",
            "\u001b[31m-          \"text\": [\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: hydra-core in /usr/local/lib/python3.12/dist-packages (1.3.2)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (2.3.0)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core) (4.9.3)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from hydra-core) (25.0)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf) (6.0.3)\\n\"\u001b[m\n",
            "\u001b[31m-          ]\u001b[m\n",
            "\u001b[31m-        }\u001b[m\n",
            "\u001b[31m-      ]\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"!pip install clearml\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"colab\": {\u001b[m\n",
            "\u001b[31m-          \"base_uri\": \"https://localhost:8080/\"\u001b[m\n",
            "\u001b[31m-        },\u001b[m\n",
            "\u001b[31m-        \"id\": \"WOzioQ7gdfYq\",\u001b[m\n",
            "\u001b[31m-        \"outputId\": \"a2e57577-f6b8-4fae-b5fa-bb77c8a0a57b\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null,\u001b[m\n",
            "\u001b[31m-      \"outputs\": [\u001b[m\n",
            "\u001b[31m-        {\u001b[m\n",
            "\u001b[31m-          \"output_type\": \"stream\",\u001b[m\n",
            "\u001b[31m-          \"name\": \"stdout\",\u001b[m\n",
            "\u001b[31m-          \"text\": [\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: clearml in /usr/local/lib/python3.12/dist-packages (2.0.2)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: attrs>=18.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (25.4.0)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: furl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.1.4)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (4.25.1)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.0.2)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: pathlib2>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.3.7.post1)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: psutil>=3.4.2 in /usr/local/lib/python3.12/dist-packages (from clearml) (5.9.5)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from clearml) (3.2.5)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.9.0.post0)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: pyjwt<2.11.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.10.1)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.12/dist-packages (from clearml) (6.0.3)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (1.17.0)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.5.0)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: Pillow>=10.3.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (11.3.0)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: referencing<0.40 in /usr/local/lib/python3.12/dist-packages (from clearml) (0.37.0)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: requests>=2.32.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.32.4)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: orderedmultidict>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from furl>=2.0.0->clearml) (1.0.1)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6.0->clearml) (2025.9.1)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6.0->clearml) (0.28.0)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing<0.40->clearml) (4.15.0)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.0->clearml) (3.4.4)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.0->clearml) (3.11)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.0->clearml) (2025.10.5)\\n\"\u001b[m\n",
            "\u001b[31m-          ]\u001b[m\n",
            "\u001b[31m-        }\u001b[m\n",
            "\u001b[31m-      ]\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"%env CLEARML_WEB_HOST=https://app.clear.ml/\\n\",\u001b[m\n",
            "\u001b[31m-        \"%env CLEARML_API_HOST=https://api.clear.ml\\n\",\u001b[m\n",
            "\u001b[31m-        \"%env CLEARML_FILES_HOST=https://files.clear.ml\\n\",\u001b[m\n",
            "\u001b[31m-        \"%env CLEARML_API_ACCESS_KEY=XGMS61QRIXH7G4URU0X7VGTDAIQUVE\\n\",\u001b[m\n",
            "\u001b[31m-        \"%env CLEARML_API_SECRET_KEY=3mpOB_Br37BLBntBoUvtxmfbBfmkbkdfRUYGje8GfL1gwe_ufJd1w4UzuQWOPaAtTWE\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"colab\": {\u001b[m\n",
            "\u001b[31m-          \"base_uri\": \"https://localhost:8080/\"\u001b[m\n",
            "\u001b[31m-        },\u001b[m\n",
            "\u001b[31m-        \"id\": \"hUj8P68pvOai\",\u001b[m\n",
            "\u001b[31m-        \"outputId\": \"d8b2fdfd-8456-475f-d7dd-ea51330257d5\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null,\u001b[m\n",
            "\u001b[31m-      \"outputs\": [\u001b[m\n",
            "\u001b[31m-        {\u001b[m\n",
            "\u001b[31m-          \"output_type\": \"stream\",\u001b[m\n",
            "\u001b[31m-          \"name\": \"stdout\",\u001b[m\n",
            "\u001b[31m-          \"text\": [\u001b[m\n",
            "\u001b[31m-            \"env: CLEARML_WEB_HOST=https://app.clear.ml/\\n\",\u001b[m\n",
            "\u001b[31m-            \"env: CLEARML_API_HOST=https://api.clear.ml\\n\",\u001b[m\n",
            "\u001b[31m-            \"env: CLEARML_FILES_HOST=https://files.clear.ml\\n\",\u001b[m\n",
            "\u001b[31m-            \"env: CLEARML_API_ACCESS_KEY=XGMS61QRIXH7G4URU0X7VGTDAIQUVE\\n\",\u001b[m\n",
            "\u001b[31m-            \"env: CLEARML_API_SECRET_KEY=3mpOB_Br37BLBntBoUvtxmfbBfmkbkdfRUYGje8GfL1gwe_ufJd1w4UzuQWOPaAtTWE\\n\"\u001b[m\n",
            "\u001b[31m-          ]\u001b[m\n",
            "\u001b[31m-        }\u001b[m\n",
            "\u001b[31m-      ]\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"from clearml import Task, Logger\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"id\": \"6_SELnD-dYv0\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null,\u001b[m\n",
            "\u001b[31m-      \"outputs\": []\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"from google.colab import drive\\n\",\u001b[m\n",
            "\u001b[31m-        \"drive.mount('/content/drive')\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"import os\\n\",\u001b[m\n",
            "\u001b[31m-        \"import hydra\\n\",\u001b[m\n",
            "\u001b[31m-        \"from omegaconf import DictConfig, OmegaConf\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"config_dir = '/content/drive/MyDrive/segmentation_project/config'\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"# Очистим и пересоздадим папку\\n\",\u001b[m\n",
            "\u001b[31m-        \"import shutil\\n\",\u001b[m\n",
            "\u001b[31m-        \"if os.path.exists(config_dir):\\n\",\u001b[m\n",
            "\u001b[31m-        \"    shutil.rmtree(config_dir)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"os.makedirs(config_dir, exist_ok=True)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"simple_config = \\\"\\\"\\\"\\n\",\u001b[m\n",
            "\u001b[31m-        \"training:\\n\",\u001b[m\n",
            "\u001b[31m-        \"  batch_size: 16\\n\",\u001b[m\n",
            "\u001b[31m-        \"  epochs: 40\\n\",\u001b[m\n",
            "\u001b[31m-        \"  learning_rate: 0.0002\\n\",\u001b[m\n",
            "\u001b[31m-        \"  optimizer: \\\"AdamW\\\"\\n\",\u001b[m\n",
            "\u001b[31m-        \"  weight_decay: 0.01\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"data:\\n\",\u001b[m\n",
            "\u001b[31m-        \"  original_images_dir: \\\"/kaggle/input/abdominalaorta/images\\\"\\n\",\u001b[m\n",
            "\u001b[31m-        \"  original_labels_dir: \\\"/kaggle/input/abdominalaorta/labels\\\"\\n\",\u001b[m\n",
            "\u001b[31m-        \"  output_base_dir: \\\"/content/base_patients\\\"\\n\",\u001b[m\n",
            "\u001b[31m-        \"  test_size: 0.2\\n\",\u001b[m\n",
            "\u001b[31m-        \"  random_state: 42\\n\",\u001b[m\n",
            "\u001b[31m-        \"  image_size: 256\\n\",\u001b[m\n",
            "\u001b[31m-        \"  num_workers: 2\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"model:\\n\",\u001b[m\n",
            "\u001b[31m-        \"  in_channel: 1\\n\",\u001b[m\n",
            "\u001b[31m-        \"  out_channel: 2\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"transforms:\\n\",\u001b[m\n",
            "\u001b[31m-        \"  image_size: 256\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\\"\\\"\\\"\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"with open(f'{config_dir}/config.yaml', 'w') as f:\\n\",\u001b[m\n",
            "\u001b[31m-        \"    f.write(simple_config)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"print(\\\"✅ Простой конфиг создан!\\\")\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"def load_hydra_config():\\n\",\u001b[m\n",
            "\u001b[31m-        \"    config_path = \\\"/content/drive/MyDrive/segmentation_project/config\\\"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    config_name = \\\"config\\\"\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    with hydra.initialize_config_dir(config_dir=config_path, version_base=\\\"1.2\\\"):\\n\",\u001b[m\n",
            "\u001b[31m-        \"        cfg = hydra.compose(config_name=config_name)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    # ОТКЛЮЧАЕМ STRICT MODE ПРОГРАММНО\\n\",\u001b[m\n",
            "\u001b[31m-        \"    OmegaConf.set_struct(cfg, False)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    return cfg\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"colab\": {\u001b[m\n",
            "\u001b[31m-          \"base_uri\": \"https://localhost:8080/\"\u001b[m\n",
            "\u001b[31m-        },\u001b[m\n",
            "\u001b[31m-        \"id\": \"I3J-8nzvrbqu\",\u001b[m\n",
            "\u001b[31m-        \"outputId\": \"f90132cd-94b5-415d-f3de-225ccc9a82a9\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null,\u001b[m\n",
            "\u001b[31m-      \"outputs\": [\u001b[m\n",
            "\u001b[31m-        {\u001b[m\n",
            "\u001b[31m-          \"output_type\": \"stream\",\u001b[m\n",
            "\u001b[31m-          \"name\": \"stdout\",\u001b[m\n",
            "\u001b[31m-          \"text\": [\u001b[m\n",
            "\u001b[31m-            \"Mounted at /content/drive\\n\",\u001b[m\n",
            "\u001b[31m-            \"✅ Простой конфиг создан!\\n\"\u001b[m\n",
            "\u001b[31m-          ]\u001b[m\n",
            "\u001b[31m-        }\u001b[m\n",
            "\u001b[31m-      ]\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"markdown\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"Разделение на train test выборку по пациентам\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"id\": \"DxpjPceMJe3L\"\u001b[m\n",
            "\u001b[31m-      }\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"def create_train_test_split_by_patient():\\n\",\u001b[m\n",
            "\u001b[31m-        \"    cfg = load_hydra_config()\\n\",\u001b[m\n",
            "\u001b[31m-        \"    patient_folders = []\\n\",\u001b[m\n",
            "\u001b[31m-        \"    for folder in os.listdir(cfg.data.original_images_dir):\\n\",\u001b[m\n",
            "\u001b[31m-        \"        folder_path = os.path.join(cfg.data.original_images_dir, folder)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        if (os.path.isdir(folder_path) and\\n\",\u001b[m\n",
            "\u001b[31m-        \"            os.path.exists(os.path.join(cfg.data.original_labels_dir, folder))):\\n\",\u001b[m\n",
            "\u001b[31m-        \"            patient_folders.append(folder)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    train_patients, test_patients = train_test_split(\\n\",\u001b[m\n",
            "\u001b[31m-        \"        patient_folders,\\n\",\u001b[m\n",
            "\u001b[31m-        \"        test_size=cfg.data.test_size,\\n\",\u001b[m\n",
            "\u001b[31m-        \"        random_state=cfg.data.random_state\\n\",\u001b[m\n",
            "\u001b[31m-        \"    )\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    train_images_dir = os.path.join(cfg.data.output_base_dir, 'train', 'images')\\n\",\u001b[m\n",
            "\u001b[31m-        \"    train_labels_dir = os.path.join(cfg.data.output_base_dir, 'train', 'labels')\\n\",\u001b[m\n",
            "\u001b[31m-        \"    test_images_dir = os.path.join(cfg.data.output_base_dir, 'test', 'images')\\n\",\u001b[m\n",
            "\u001b[31m-        \"    test_labels_dir = os.path.join(cfg.data.output_base_dir, 'test', 'labels')\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    for dir_path in [train_images_dir, train_labels_dir, test_images_dir, test_labels_dir]:\\n\",\u001b[m\n",
            "\u001b[31m-        \"        os.makedirs(dir_path, exist_ok=True)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    def copy_patient_files(patients, src_images_dir, src_labels_dir, dst_images_dir, dst_labels_dir):\\n\",\u001b[m\n",
            "\u001b[31m-        \"        total_files = 0\\n\",\u001b[m\n",
            "\u001b[31m-        \"        for patient in patients:\\n\",\u001b[m\n",
            "\u001b[31m-        \"            patient_images_dir = os.path.join(src_images_dir, patient)\\n\",\u001b[m\n",
            "\u001b[31m-        \"            patient_labels_dir = os.path.join(src_labels_dir, patient)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"            for file in os.listdir(patient_images_dir):\\n\",\u001b[m\n",
            "\u001b[31m-        \"                if file.endswith('.png'):\\n\",\u001b[m\n",
            "\u001b[31m-        \"                    src_image_path = os.path.join(patient_images_dir, file)\\n\",\u001b[m\n",
            "\u001b[31m-        \"                    dst_image_path = os.path.join(dst_images_dir, f\\\"{patient}_{file}\\\")\\n\",\u001b[m\n",
            "\u001b[31m-        \"                    shutil.copy2(src_image_path, dst_image_path)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"                    src_label_path = os.path.join(patient_labels_dir, file)\\n\",\u001b[m\n",
            "\u001b[31m-        \"                    dst_label_path = os.path.join(dst_labels_dir, f\\\"{patient}_{file}\\\")\\n\",\u001b[m\n",
            "\u001b[31m-        \"                    shutil.copy2(src_label_path, dst_label_path)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"                    total_files += 1\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        return total_files\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    train_total = copy_patient_files(train_patients, cfg.data.original_images_dir, cfg.data.original_labels_dir,\\n\",\u001b[m\n",
            "\u001b[31m-        \"                                   train_images_dir, train_labels_dir)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    test_total = copy_patient_files(test_patients, cfg.data.original_images_dir, cfg.data.original_labels_dir,\\n\",\u001b[m\n",
            "\u001b[31m-        \"                                  test_images_dir, test_labels_dir)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    return {\\n\",\u001b[m\n",
            "\u001b[31m-        \"        'train_images': train_images_dir,\\n\",\u001b[m\n",
            "\u001b[31m-        \"        'train_labels': train_labels_dir,\\n\",\u001b[m\n",
            "\u001b[31m-        \"        'test_images': test_images_dir,\\n\",\u001b[m\n",
            "\u001b[31m-        \"        'test_labels': test_labels_dir,\\n\",\u001b[m\n",
            "\u001b[31m-        \"        'train_patients': train_patients,\\n\",\u001b[m\n",
            "\u001b[31m-        \"        'test_patients': test_patients\\n\",\u001b[m\n",
            "\u001b[31m-        \"    }\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"trusted\": true,\u001b[m\n",
            "\u001b[31m-        \"execution\": {\u001b[m\n",
            "\u001b[31m-          \"iopub.status.busy\": \"2025-11-15T07:29:38.174796Z\",\u001b[m\n",
            "\u001b[31m-          \"iopub.execute_input\": \"2025-11-15T07:29:38.175296Z\",\u001b[m\n",
            "\u001b[31m-          \"iopub.status.idle\": \"2025-11-15T07:29:38.187116Z\",\u001b[m\n",
            "\u001b[31m-          \"shell.execute_reply.started\": \"2025-11-15T07:29:38.175273Z\",\u001b[m\n",
            "\u001b[31m-          \"shell.execute_reply\": \"2025-11-15T07:29:38.186273Z\"\u001b[m\n",
            "\u001b[31m-        },\u001b[m\n",
            "\u001b[31m-        \"id\": \"zNBbqzptObnZ\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"outputs\": [],\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"markdown\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"Датасет\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"id\": \"ohC3O2TgJoZ7\"\u001b[m\n",
            "\u001b[31m-      }\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"class SegmentationDataset(Dataset):\\n\",\u001b[m\n",
            "\u001b[31m-        \"    def __init__(self, images_dir, labels_dir, transform=None):\\n\",\u001b[m\n",
            "\u001b[31m-        \"        self.images_dir = images_dir\\n\",\u001b[m\n",
            "\u001b[31m-        \"        self.labels_dir = labels_dir\\n\",\u001b[m\n",
            "\u001b[31m-        \"        self.transform = transform\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        self.image_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.png')])\\n\",\u001b[m\n",
            "\u001b[31m-        \"        self.label_files = sorted([f for f in os.listdir(labels_dir) if f.endswith('.png')])\\n\",\u001b[m\n",
            "\u001b[31m-        \"    def __len__(self):\\n\",\u001b[m\n",
            "\u001b[31m-        \"        return len(self.image_files)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    def __getitem__(self, idx):\\n\",\u001b[m\n",
            "\u001b[31m-        \"        image_path = os.path.join(self.images_dir, self.image_files[idx])\\n\",\u001b[m\n",
            "\u001b[31m-        \"        label_path = os.path.join(self.labels_dir, self.label_files[idx])\\n\",\u001b[m\n",
            "\u001b[31m-        \"        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        if self.transform:\\n\",\u001b[m\n",
            "\u001b[31m-        \"            transformed = self.transform(image=image, mask=label)\\n\",\u001b[m\n",
            "\u001b[31m-        \"            image = transformed['image']\\n\",\u001b[m\n",
            "\u001b[31m-        \"            label = transformed['mask']\\n\",\u001b[m\n",
            "\u001b[31m-        \"        label = (label > 0).long()\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        return image, label\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"trusted\": true,\u001b[m\n",
            "\u001b[31m-        \"execution\": {\u001b[m\n",
            "\u001b[31m-          \"iopub.status.busy\": \"2025-11-15T07:29:38.188095Z\",\u001b[m\n",
            "\u001b[31m-          \"iopub.execute_input\": \"2025-11-15T07:29:38.188463Z\",\u001b[m\n",
            "\u001b[31m-          \"iopub.status.idle\": \"2025-11-15T07:29:38.256584Z\",\u001b[m\n",
            "\u001b[31m-          \"shell.execute_reply.started\": \"2025-11-15T07:29:38.188439Z\",\u001b[m\n",
            "\u001b[31m-          \"shell.execute_reply\": \"2025-11-15T07:29:38.255572Z\"\u001b[m\n",
            "\u001b[31m-        },\u001b[m\n",
            "\u001b[31m-        \"id\": \"yycXtF2gObnZ\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"outputs\": [],\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"markdown\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"Модель Unet\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"id\": \"8NpnAj2lJw2h\"\u001b[m\n",
            "\u001b[31m-      }\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"import torch\\n\",\u001b[m\n",
            "\u001b[31m-        \"import torch.nn as nn\\n\",\u001b[m\n",
            "\u001b[31m-        \"import torch.nn.functional as F\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"class UNet(nn.Module):\\n\",\u001b[m\n",
            "\u001b[31m-        \"    def contracting_block(self, in_channels, out_channels, kernel_size=3):\\n\",\u001b[m\n",
            "\u001b[31m-        \"        block = torch.nn.Sequential(\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=1),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.ReLU(),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.BatchNorm2d(out_channels),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels, padding=1),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.ReLU(),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.BatchNorm2d(out_channels),\\n\",\u001b[m\n",
            "\u001b[31m-        \"        )\\n\",\u001b[m\n",
            "\u001b[31m-        \"        return block\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\\n\",\u001b[m\n",
            "\u001b[31m-        \"        block = torch.nn.Sequential(\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.ReLU(),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.BatchNorm2d(mid_channel),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.ReLU(),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.BatchNorm2d(mid_channel),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=2, stride=2)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        )\\n\",\u001b[m\n",
            "\u001b[31m-        \"        return block\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\\n\",\u001b[m\n",
            "\u001b[31m-        \"        block = torch.nn.Sequential(\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.ReLU(),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.BatchNorm2d(mid_channel),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.ReLU(),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.BatchNorm2d(mid_channel),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\\n\",\u001b[m\n",
            "\u001b[31m-        \"        )\\n\",\u001b[m\n",
            "\u001b[31m-        \"        return block\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    def __init__(self, in_channel, out_channel):\\n\",\u001b[m\n",
            "\u001b[31m-        \"        super(UNet, self).__init__()\\n\",\u001b[m\n",
            "\u001b[31m-        \"        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        self.conv_encode2 = self.contracting_block(64, 128)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        self.conv_encode3 = self.contracting_block(128, 256)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        self.bottleneck = torch.nn.Sequential(\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.Conv2d(kernel_size=3, in_channels=256, out_channels=512, padding=1),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.ReLU(),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.BatchNorm2d(512),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512, padding=1),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.ReLU(),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.BatchNorm2d(512),\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        )\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        self.conv_decode3 = self.expansive_block(512, 256, 128)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        self.conv_decode2 = self.expansive_block(256, 128, 64)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        self.final_layer = self.final_block(128, 64, out_channel)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    def crop_and_concat(self, upsampled, bypass):\\n\",\u001b[m\n",
            "\u001b[31m-        \"        _, _, h_up, w_up = upsampled.size()\\n\",\u001b[m\n",
            "\u001b[31m-        \"        _, _, h_by, w_by = bypass.size()\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        crop_h = (h_by - h_up) // 2\\n\",\u001b[m\n",
            "\u001b[31m-        \"        crop_w = (w_by - w_up) // 2\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        bypass_cropped = bypass[:, :,\\n\",\u001b[m\n",
            "\u001b[31m-        \"                              crop_h:crop_h + h_up,\\n\",\u001b[m\n",
            "\u001b[31m-        \"                              crop_w:crop_w + w_up]\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        return torch.cat((upsampled, bypass_cropped), 1)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    def forward(self, x):\\n\",\u001b[m\n",
            "\u001b[31m-        \"        encode_block1 = self.conv_encode1(x)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        encode_pool1 = self.conv_maxpool1(encode_block1)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        encode_block2 = self.conv_encode2(encode_pool1)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        encode_pool2 = self.conv_maxpool2(encode_block2)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        encode_block3 = self.conv_encode3(encode_pool2)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        encode_pool3 = self.conv_maxpool3(encode_block3)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        bottleneck1 = self.bottleneck(encode_pool3)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        cat_layer2 = self.conv_decode3(decode_block3)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        cat_layer1 = self.conv_decode2(decode_block2)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        final_layer = self.final_layer(decode_block1)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        return final_layer\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"trusted\": true,\u001b[m\n",
            "\u001b[31m-        \"execution\": {\u001b[m\n",
            "\u001b[31m-          \"iopub.status.busy\": \"2025-11-15T07:29:38.257612Z\",\u001b[m\n",
            "\u001b[31m-          \"iopub.execute_input\": \"2025-11-15T07:29:38.257905Z\",\u001b[m\n",
            "\u001b[31m-          \"iopub.status.idle\": \"2025-11-15T07:29:38.280443Z\",\u001b[m\n",
            "\u001b[31m-          \"shell.execute_reply.started\": \"2025-11-15T07:29:38.257873Z\",\u001b[m\n",
            "\u001b[31m-          \"shell.execute_reply\": \"2025-11-15T07:29:38.279547Z\"\u001b[m\n",
            "\u001b[31m-        },\u001b[m\n",
            "\u001b[31m-        \"id\": \"U7O5qetOObna\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"outputs\": [],\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"markdown\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"Аугментация и предподготовка\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"id\": \"g5YUhSiGJ0tL\"\u001b[m\n",
            "\u001b[31m-      }\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"import albumentations as A\\n\",\u001b[m\n",
            "\u001b[31m-        \"from albumentations.pytorch import ToTensorV2\\n\",\u001b[m\n",
            "\u001b[31m-        \"import cv2\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"def transformers():\\n\",\u001b[m\n",
            "\u001b[31m-        \"    cfg = load_hydra_config()\\n\",\u001b[m\n",
            "\u001b[31m-        \"    train_transform = A.Compose([\\n\",\u001b[m\n",
            "\u001b[31m-        \"        A.Resize(height=cfg.transforms.image_size, width=cfg.transforms.image_size),\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        A.HorizontalFlip(p=0.5),\\n\",\u001b[m\n",
            "\u001b[31m-        \"        A.VerticalFlip(p=0.3),\\n\",\u001b[m\n",
            "\u001b[31m-        \"        A.RandomRotate90(p=0.5),\\n\",\u001b[m\n",
            "\u001b[31m-        \"        A.ShiftScaleRotate(\\n\",\u001b[m\n",
            "\u001b[31m-        \"            shift_limit=0.05,\\n\",\u001b[m\n",
            "\u001b[31m-        \"            scale_limit=0.1,\\n\",\u001b[m\n",
            "\u001b[31m-        \"            rotate_limit=10,\\n\",\u001b[m\n",
            "\u001b[31m-        \"            p=0.5\\n\",\u001b[m\n",
            "\u001b[31m-        \"        ),\\n\",\u001b[m\n",
            "\u001b[31m-        \"        A.RandomBrightnessContrast(\\n\",\u001b[m\n",
            "\u001b[31m-        \"            brightness_limit=0.1,\\n\",\u001b[m\n",
            "\u001b[31m-        \"            contrast_limit=0.1,\\n\",\u001b[m\n",
            "\u001b[31m-        \"            p=0.3\\n\",\u001b[m\n",
            "\u001b[31m-        \"        ),\\n\",\u001b[m\n",
            "\u001b[31m-        \"        A.GaussNoise(var_limit=(10.0, 30.0), mean=0, p=0.2),\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        A.Normalize(mean=[0.5], std=[0.5]),\\n\",\u001b[m\n",
            "\u001b[31m-        \"        ToTensorV2(),\\n\",\u001b[m\n",
            "\u001b[31m-        \"    ])\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    val_transform = A.Compose([\\n\",\u001b[m\n",
            "\u001b[31m-        \"        A.Resize(height=cfg.transforms.image_size, width=cfg.transforms.image_size),\\n\",\u001b[m\n",
            "\u001b[31m-        \"        A.Normalize(mean=[0.5], std=[0.5]),\\n\",\u001b[m\n",
            "\u001b[31m-        \"        ToTensorV2(),\\n\",\u001b[m\n",
            "\u001b[31m-        \"    ])\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    return train_transform, val_transform\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"trusted\": true,\u001b[m\n",
            "\u001b[31m-        \"execution\": {\u001b[m\n",
            "\u001b[31m-          \"iopub.status.busy\": \"2025-11-15T07:29:38.283090Z\",\u001b[m\n",
            "\u001b[31m-          \"iopub.execute_input\": \"2025-11-15T07:29:38.283404Z\",\u001b[m\n",
            "\u001b[31m-          \"iopub.status.idle\": \"2025-11-15T07:29:39.509192Z\",\u001b[m\n",
            "\u001b[31m-          \"shell.execute_reply.started\": \"2025-11-15T07:29:38.283347Z\",\u001b[m\n",
            "\u001b[31m-          \"shell.execute_reply\": \"2025-11-15T07:29:39.508032Z\"\u001b[m\n",
            "\u001b[31m-        },\u001b[m\n",
            "\u001b[31m-        \"id\": \"oaDmNuPsObna\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"outputs\": [],\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"def dice_score_ce(predictions, targets, smooth=1e-6):\\n\",\u001b[m\n",
            "\u001b[31m-        \"    probs = torch.softmax(predictions, dim=1)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    pred_probs = probs[:, 1]\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    pred_binary = torch.argmax(probs, dim=1)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    pred_flat = pred_binary.flatten(1)\\n\",\u001b[m\n",
            "\u001b[31m-        \"    target_flat = targets.flatten(1)\\n\",\u001b[m\n",
            "\u001b[31m-        \"    intersection = (pred_flat * target_flat).sum(1)\\n\",\u001b[m\n",
            "\u001b[31m-        \"    union = pred_flat.sum(1) + target_flat.sum(1)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    dice = (2. * intersection + smooth) / (union + smooth)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    return dice.mean()\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"trusted\": true,\u001b[m\n",
            "\u001b[31m-        \"execution\": {\u001b[m\n",
            "\u001b[31m-          \"iopub.status.busy\": \"2025-11-15T07:30:15.300925Z\",\u001b[m\n",
            "\u001b[31m-          \"iopub.execute_input\": \"2025-11-15T07:30:15.301274Z\",\u001b[m\n",
            "\u001b[31m-          \"iopub.status.idle\": \"2025-11-15T07:30:15.317891Z\",\u001b[m\n",
            "\u001b[31m-          \"shell.execute_reply.started\": \"2025-11-15T07:30:15.301243Z\",\u001b[m\n",
            "\u001b[31m-          \"shell.execute_reply\": \"2025-11-15T07:30:15.316780Z\"\u001b[m\n",
            "\u001b[31m-        },\u001b[m\n",
            "\u001b[31m-        \"id\": \"gOqHBIHpObnb\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"outputs\": [],\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"!pip install torchmetrics\\n\",\u001b[m\n",
            "\u001b[31m-        \"from torchmetrics import JaccardIndex\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"from torchmetrics.segmentation import DiceScore\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"from torchmetrics.classification import BinaryPrecision, BinaryRecall, BinaryF1Score\\n\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"colab\": {\u001b[m\n",
            "\u001b[31m-          \"base_uri\": \"https://localhost:8080/\"\u001b[m\n",
            "\u001b[31m-        },\u001b[m\n",
            "\u001b[31m-        \"id\": \"qiuvASFAgnXF\",\u001b[m\n",
            "\u001b[31m-        \"outputId\": \"dbc86f82-1def-466f-d040-9580ac6e259e\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null,\u001b[m\n",
            "\u001b[31m-      \"outputs\": [\u001b[m\n",
            "\u001b[31m-        {\u001b[m\n",
            "\u001b[31m-          \"output_type\": \"stream\",\u001b[m\n",
            "\u001b[31m-          \"name\": \"stdout\",\u001b[m\n",
            "\u001b[31m-          \"text\": [\u001b[m\n",
            "\u001b[31m-            \"Collecting torchmetrics\\n\",\u001b[m\n",
            "\u001b[31m-            \"  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Collecting lightning-utilities>=0.8.0 (from torchmetrics)\\n\",\u001b[m\n",
            "\u001b[31m-            \"  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\\n\",\u001b[m\n",
            "\u001b[31m-            \"\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m983.2/983.2 kB\\u001b[0m \\u001b[31m24.2 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\u001b[m\n",
            "\u001b[31m-            \"\\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\\n\",\u001b[m\n",
            "\u001b[31m-            \"Installing collected packages: lightning-utilities, torchmetrics\\n\",\u001b[m\n",
            "\u001b[31m-            \"Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\\n\"\u001b[m\n",
            "\u001b[31m-          ]\u001b[m\n",
            "\u001b[31m-        }\u001b[m\n",
            "\u001b[31m-      ]\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"iou_metric = JaccardIndex(task='binary')  # или task='multiclass', num_classes=2\\n\",\u001b[m\n",
            "\u001b[31m-        \"dice_metric = DiceScore(num_classes=2, average='micro', input_format='index')\\n\",\u001b[m\n",
            "\u001b[31m-        \"precision_metric = BinaryPrecision()\\n\",\u001b[m\n",
            "\u001b[31m-        \"recall_metric = BinaryRecall()\\n\",\u001b[m\n",
            "\u001b[31m-        \"f1_metric = BinaryF1Score()\\n\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"colab\": {\u001b[m\n",
            "\u001b[31m-          \"base_uri\": \"https://localhost:8080/\"\u001b[m\n",
            "\u001b[31m-        },\u001b[m\n",
            "\u001b[31m-        \"id\": \"m60AWWZsojRT\",\u001b[m\n",
            "\u001b[31m-        \"outputId\": \"99b50432-dcd6-4660-d5d2-779bd9b01472\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null,\u001b[m\n",
            "\u001b[31m-      \"outputs\": [\u001b[m\n",
            "\u001b[31m-        {\u001b[m\n",
            "\u001b[31m-          \"output_type\": \"stream\",\u001b[m\n",
            "\u001b[31m-          \"name\": \"stderr\",\u001b[m\n",
            "\u001b[31m-          \"text\": [\u001b[m\n",
            "\u001b[31m-            \"/usr/local/lib/python3.12/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: DiceScore metric currently defaults to `average=micro`, but will change to`average=macro` in the v1.9 release. If you've explicitly set this parameter, you can ignore this warning.\\n\",\u001b[m\n",
            "\u001b[31m-            \"  warnings.warn(*args, **kwargs)\\n\"\u001b[m\n",
            "\u001b[31m-          ]\u001b[m\n",
            "\u001b[31m-        }\u001b[m\n",
            "\u001b[31m-      ]\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"def train_model():\\n\",\u001b[m\n",
            "\u001b[31m-        \"    cfg = load_hydra_config()\\n\",\u001b[m\n",
            "\u001b[31m-        \"    task = Task.init(\\n\",\u001b[m\n",
            "\u001b[31m-        \"        project_name=\\\"MedicalSegmentation\\\",\\n\",\u001b[m\n",
            "\u001b[31m-        \"        task_name=f\\\"UNet_{cfg.training.epochs}epochs\\\",\\n\",\u001b[m\n",
            "\u001b[31m-        \"        auto_connect_frameworks={'pytorch': True, 'hydra': True}\\n\",\u001b[m\n",
            "\u001b[31m-        \"    )\\n\",\u001b[m\n",
            "\u001b[31m-        \"    cfg_dict = OmegaConf.to_container(cfg, resolve=True)\\n\",\u001b[m\n",
            "\u001b[31m-        \"    task.connect_configuration(cfg_dict)\\n\",\u001b[m\n",
            "\u001b[31m-        \"    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n\",\u001b[m\n",
            "\u001b[31m-        \"    paths = create_train_test_split_by_patient()\\n\",\u001b[m\n",
            "\u001b[31m-        \"    train_transform, val_transform = transformers()\\n\",\u001b[m\n",
            "\u001b[31m-        \"    train_dataset = SegmentationDataset(\\n\",\u001b[m\n",
            "\u001b[31m-        \"        images_dir=paths['train_images'],\\n\",\u001b[m\n",
            "\u001b[31m-        \"        labels_dir=paths['train_labels'],\\n\",\u001b[m\n",
            "\u001b[31m-        \"        transform=train_transform\\n\",\u001b[m\n",
            "\u001b[31m-        \"    )\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    test_dataset = SegmentationDataset(\\n\",\u001b[m\n",
            "\u001b[31m-        \"        images_dir=paths['test_images'],\\n\",\u001b[m\n",
            "\u001b[31m-        \"        labels_dir=paths['test_labels'],\\n\",\u001b[m\n",
            "\u001b[31m-        \"        transform=val_transform\\n\",\u001b[m\n",
            "\u001b[31m-        \"    )\\n\",\u001b[m\n",
            "\u001b[31m-        \"    train_loader = DataLoader(\\n\",\u001b[m\n",
            "\u001b[31m-        \"        train_dataset,\\n\",\u001b[m\n",
            "\u001b[31m-        \"        batch_size=cfg.training.batch_size,\\n\",\u001b[m\n",
            "\u001b[31m-        \"        shuffle=True,\\n\",\u001b[m\n",
            "\u001b[31m-        \"        num_workers=cfg.data.num_workers\\n\",\u001b[m\n",
            "\u001b[31m-        \"    )\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    test_loader = DataLoader(\\n\",\u001b[m\n",
            "\u001b[31m-        \"        test_dataset,\\n\",\u001b[m\n",
            "\u001b[31m-        \"        batch_size=cfg.training.batch_size,\\n\",\u001b[m\n",
            "\u001b[31m-        \"        shuffle=False,\\n\",\u001b[m\n",
            "\u001b[31m-        \"        num_workers=cfg.data.num_workers\\n\",\u001b[m\n",
            "\u001b[31m-        \"    )\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    model = UNet(cfg.model.in_channel, cfg.model.out_channel).to(device)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"    criterion = nn.CrossEntropyLoss()\\n\",\u001b[m\n",
            "\u001b[31m-        \"    optimizer = torch.optim.AdamW(\\n\",\u001b[m\n",
            "\u001b[31m-        \"        model.parameters(),\\n\",\u001b[m\n",
            "\u001b[31m-        \"        lr=cfg.training.learning_rate,\\n\",\u001b[m\n",
            "\u001b[31m-        \"        weight_decay=cfg.training.weight_decay\\n\",\u001b[m\n",
            "\u001b[31m-        \"    )\\n\",\u001b[m\n",
            "\u001b[31m-        \"    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\\n\",\u001b[m\n",
            "\u001b[31m-        \"                                                          mode='min')\\n\",\u001b[m\n",
            "\u001b[31m-        \"    train_losses = []\\n\",\u001b[m\n",
            "\u001b[31m-        \"    val_dice_scores = []\\n\",\u001b[m\n",
            "\u001b[31m-        \"    for epoch in range(cfg.training.epochs):\\n\",\u001b[m\n",
            "\u001b[31m-        \"        model.train()\\n\",\u001b[m\n",
            "\u001b[31m-        \"        epoch_train_loss = 0\\n\",\u001b[m\n",
            "\u001b[31m-        \"        train_pbar = tqdm(train_loader,desc=f'Epoch {epoch}/{cfg.training.epochs} [Train]')\\n\",\u001b[m\n",
            "\u001b[31m-        \"        for idx, (images, labels) in enumerate(train_pbar):\\n\",\u001b[m\n",
            "\u001b[31m-        \"            images, labels = images.to(device), labels.to(device)\\n\",\u001b[m\n",
            "\u001b[31m-        \"            labels = labels.long()\\n\",\u001b[m\n",
            "\u001b[31m-        \"            optimizer.zero_grad()\\n\",\u001b[m\n",
            "\u001b[31m-        \"            output = model(images)\\n\",\u001b[m\n",
            "\u001b[31m-        \"            loss = criterion(output, labels)\\n\",\u001b[m\n",
            "\u001b[31m-        \"            loss.backward()\\n\",\u001b[m\n",
            "\u001b[31m-        \"            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\\n\",\u001b[m\n",
            "\u001b[31m-        \"            optimizer.step()\\n\",\u001b[m\n",
            "\u001b[31m-        \"            epoch_train_loss += loss.item()\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"            train_pbar.set_postfix({\\n\",\u001b[m\n",
            "\u001b[31m-        \"                'Loss': f'{loss.item():.4f}',\\n\",\u001b[m\n",
            "\u001b[31m-        \"                'Avg Loss': f'{epoch_train_loss/(idx+1):.4f}'\\n\",\u001b[m\n",
            "\u001b[31m-        \"            })\\n\",\u001b[m\n",
            "\u001b[31m-        \"        train_pbar.close()\\n\",\u001b[m\n",
            "\u001b[31m-        \"        avg_train_loss = epoch_train_loss / len(train_loader)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        model.eval()\\n\",\u001b[m\n",
            "\u001b[31m-        \"        epoch_val_dice = 0\\n\",\u001b[m\n",
            "\u001b[31m-        \"        val_batches = 0\\n\",\u001b[m\n",
            "\u001b[31m-        \"        val_pbar = tqdm(test_loader, desc=f'Epoch {epoch+1}/{cfg.training.epochs} [Val]')\\n\",\u001b[m\n",
            "\u001b[31m-        \"        with torch.no_grad():\\n\",\u001b[m\n",
            "\u001b[31m-        \"            for idx, (images, masks) in enumerate(val_pbar):\\n\",\u001b[m\n",
            "\u001b[31m-        \"                images, masks = images.to(device), masks.to(device)\\n\",\u001b[m\n",
            "\u001b[31m-        \"                masks = masks.long()\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"                outputs = model(images)\\n\",\u001b[m\n",
            "\u001b[31m-        \"                probs = torch.softmax(outputs, dim=1)\\n\",\u001b[m\n",
            "\u001b[31m-        \"                preds = torch.argmax(probs, dim=1)\\n\",\u001b[m\n",
            "\u001b[31m-        \"                masks = masks.long()\\n\",\u001b[m\n",
            "\u001b[31m-        \"                masks = masks.unsqueeze(1)\\n\",\u001b[m\n",
            "\u001b[31m-        \"                preds = preds.squeeze(1)\\n\",\u001b[m\n",
            "\u001b[31m-        \"                dice_metric.update(outputs, masks)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"                val_batches += 1\\n\",\u001b[m\n",
            "\u001b[31m-        \"                val_pbar.set_postfix({\\n\",\u001b[m\n",
            "\u001b[31m-        \"                    'Dice': f'{dice_metric.item():.4f}',\\n\",\u001b[m\n",
            "\u001b[31m-        \"                    'Avg Dice': f'{epoch_val_dice/(idx+1):.4f}'\\n\",\u001b[m\n",
            "\u001b[31m-        \"                })\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        val_pbar.close()\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\",\u001b[m\n",
            "\u001b[31m-        \"        avg_train_loss = epoch_train_loss / len(train_loader)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        avg_val_dice = dice_metric.compute()\\n\",\u001b[m\n",
            "\u001b[31m-        \"        logger = Logger.current_logger()\\n\",\u001b[m\n",
            "\u001b[31m-        \"        logger.report_scalar(\\\"Loss\\\", \\\"Train\\\", avg_train_loss, epoch)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        logger.report_scalar(\\\"Metrics\\\", \\\"Dice\\\", avg_val_dice, epoch)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        train_losses.append(avg_train_loss)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        val_dice_scores.append(avg_val_dice)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        scheduler.step(avg_train_loss)\\n\",\u001b[m\n",
            "\u001b[31m-        \"        print(f'Epoch {epoch:03d}:')\\n\",\u001b[m\n",
            "\u001b[31m-        \"        print(f'  Loss: {avg_train_loss:.4f}')\\n\",\u001b[m\n",
            "\u001b[31m-        \"        print(f'  Dice: {avg_val_dice:.4f}')\\n\",\u001b[m\n",
            "\u001b[31m-        \"        print(f'  LR:   {optimizer.param_groups[0][\\\"lr\\\"]:.2e}')\\n\",\u001b[m\n",
            "\u001b[31m-        \"        print('-' * 40)\\n\",\u001b[m\n",
            "\u001b[31m-        \"\\n\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"trusted\": true,\u001b[m\n",
            "\u001b[31m-        \"execution\": {\u001b[m\n",
            "\u001b[31m-          \"iopub.status.busy\": \"2025-11-15T07:30:15.318893Z\",\u001b[m\n",
            "\u001b[31m-          \"iopub.execute_input\": \"2025-11-15T07:30:15.319193Z\",\u001b[m\n",
            "\u001b[31m-          \"iopub.status.idle\": \"2025-11-15T07:30:15.339812Z\",\u001b[m\n",
            "\u001b[31m-          \"shell.execute_reply.started\": \"2025-11-15T07:30:15.319169Z\",\u001b[m\n",
            "\u001b[31m-          \"shell.execute_reply\": \"2025-11-15T07:30:15.338997Z\"\u001b[m\n",
            "\u001b[31m-        },\u001b[m\n",
            "\u001b[31m-        \"id\": \"subI8KbrObnb\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"outputs\": [],\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [\u001b[m\n",
            "\u001b[31m-        \"if __name__ == \\\"__main__\\\":\\n\",\u001b[m\n",
            "\u001b[31m-        \"    results = train_model()\"\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"trusted\": true,\u001b[m\n",
            "\u001b[31m-        \"execution\": {\u001b[m\n",
            "\u001b[31m-          \"iopub.status.busy\": \"2025-11-15T07:30:15.340811Z\",\u001b[m\n",
            "\u001b[31m-          \"iopub.execute_input\": \"2025-11-15T07:30:15.341141Z\",\u001b[m\n",
            "\u001b[31m-          \"execution_failed\": \"2025-11-15T10:47:36.006Z\"\u001b[m\n",
            "\u001b[31m-        },\u001b[m\n",
            "\u001b[31m-        \"colab\": {\u001b[m\n",
            "\u001b[31m-          \"base_uri\": \"https://localhost:8080/\"\u001b[m\n",
            "\u001b[31m-        },\u001b[m\n",
            "\u001b[31m-        \"id\": \"8o6KyklqObnb\",\u001b[m\n",
            "\u001b[31m-        \"outputId\": \"95427098-2251-45f9-8fe7-d20709b9a3cd\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"outputs\": [\u001b[m\n",
            "\u001b[31m-        {\u001b[m\n",
            "\u001b[31m-          \"output_type\": \"stream\",\u001b[m\n",
            "\u001b[31m-          \"name\": \"stderr\",\u001b[m\n",
            "\u001b[31m-          \"text\": [\u001b[m\n",
            "\u001b[31m-            \"/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning:\\n\",\u001b[m\n",
            "\u001b[31m-            \"\\n\",\u001b[m\n",
            "\u001b[31m-            \"ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\\n\",\u001b[m\n",
            "\u001b[31m-            \"\\n\",\u001b[m\n",
            "\u001b[31m-            \"/tmp/ipython-input-2562268279.py:24: UserWarning:\\n\",\u001b[m\n",
            "\u001b[31m-            \"\\n\",\u001b[m\n",
            "\u001b[31m-            \"Argument(s) 'var_limit, mean' are not valid for transform GaussNoise\\n\",\u001b[m\n",
            "\u001b[31m-            \"\\n\",\u001b[m\n",
            "\u001b[31m-            \"Epoch 0/40 [Train]:  92%|█████████▏| 229/250 [02:56<00:15,  1.33it/s, Loss=0.0937, Avg Loss=0.3684]\"\u001b[m\n",
            "\u001b[31m-          ]\u001b[m\n",
            "\u001b[31m-        }\u001b[m\n",
            "\u001b[31m-      ],\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null\u001b[m\n",
            "\u001b[31m-    },\u001b[m\n",
            "\u001b[31m-    {\u001b[m\n",
            "\u001b[31m-      \"cell_type\": \"code\",\u001b[m\n",
            "\u001b[31m-      \"source\": [],\u001b[m\n",
            "\u001b[31m-      \"metadata\": {\u001b[m\n",
            "\u001b[31m-        \"id\": \"RzKrez9wtmoa\"\u001b[m\n",
            "\u001b[31m-      },\u001b[m\n",
            "\u001b[31m-      \"execution_count\": null,\u001b[m\n",
            "\u001b[31m-      \"outputs\": []\u001b[m\n",
            "\u001b[31m-    }\u001b[m\n",
            "\u001b[31m-  ]\u001b[m\n",
            "\u001b[31m-}\u001b[m\n",
            "\\ No newline at end of file\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m{\"metadata\":{\"kernelspec\":{\"display_name\":\"Python 3\",\"name\":\"python3\"},\"language_info\":{\"name\":\"python\",\"version\":\"3.11.13\",\"mimetype\":\"text/x-python\",\"codemirror_mode\":{\"name\":\"ipython\",\"version\":3},\"pygments_lexer\":\"ipython3\",\"nbconvert_exporter\":\"python\",\"file_extension\":\".py\"},\"kaggle\":{\"accelerator\":\"none\",\"dataSources\":[{\"sourceId\":13734718,\"sourceType\":\"datasetVersion\",\"datasetId\":8738907}],\"dockerImageVersionId\":31192,\"isInternetEnabled\":true,\"language\":\"python\",\"sourceType\":\"notebook\",\"isGpuEnabled\":false},\"colab\":{\"provenance\":[],\"gpuType\":\"T4\"},\"accelerator\":\"GPU\"},\"nbformat_minor\":0,\"nbformat\":4,\"cells\":[{\"cell_type\":\"markdown\",\"source\":[\"Импорт библиотек\"],\"metadata\":{\"id\":\"KfVqj6hhJWaU\"}},{\"cell_type\":\"code\",\"source\":[\"import torch\\n\",\"from torch.utils.data import Dataset, DataLoader\\n\",\"from PIL import Image\\n\",\"import torchvision.transforms as transforms\\n\",\"import numpy as np\\n\",\"import pandas as pd\\n\",\"import os\\n\",\"import scipy.io\\n\",\"import matplotlib.pyplot as plt\\n\",\"from tqdm import tqdm\\n\",\"import torch.nn as nn\\n\",\"import torch.nn.functional as F\\n\",\"from sklearn.model_selection import train_test_split\\n\",\"import shutil\"],\"metadata\":{\"trusted\":true,\"execution\":{\"iopub.status.busy\":\"2025-11-15T07:29:31.131600Z\",\"iopub.execute_input\":\"2025-11-15T07:29:31.131962Z\",\"iopub.status.idle\":\"2025-11-15T07:29:38.173868Z\",\"shell.execute_reply.started\":\"2025-11-15T07:29:31.131926Z\",\"shell.execute_reply\":\"2025-11-15T07:29:38.173001Z\"},\"id\":\"AbrPBBBBObnY\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763464212392,\"user_tz\":-180,\"elapsed\":217,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}}},\"outputs\":[],\"execution_count\":3},{\"cell_type\":\"markdown\",\"source\":[\"Путь датасета с kaggle\"],\"metadata\":{\"id\":\"G9XJZ0byJaYR\"}},{\"cell_type\":\"code\",\"source\":[\"import kagglehub\\n\",\"\\n\",\"# Download latest version\\n\",\"path = kagglehub.dataset_download(\\\"miniredtrout/abdominalaorta\\\")\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"C1y9iTbfQQXr\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763464216398,\"user_tz\":-180,\"elapsed\":4003,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}},\"outputId\":\"cc6cda22-c6c0-476a-de21-d4acc88663ac\"},\"execution_count\":4,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Using Colab cache for faster access to the 'abdominalaorta' dataset.\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"path\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\",\"height\":35},\"id\":\"35HxSbGIRI_2\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763464216408,\"user_tz\":-180,\"elapsed\":5,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}},\"outputId\":\"2f8176ff-9c6f-4e70-a34a-554a295d4977\"},\"execution_count\":5,\"outputs\":[{\"output_type\":\"execute_result\",\"data\":{\"text/plain\":[\"'/kaggle/input/abdominalaorta'\"],\"application/vnd.google.colaboratory.intrinsic+json\":{\"type\":\"string\"}},\"metadata\":{},\"execution_count\":5}]},{\"cell_type\":\"code\",\"source\":[\"!pip install hydra-core omegaconf\\n\",\"import hydra\\n\",\"from omegaconf import DictConfig, OmegaConf\\n\",\"import os\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"6dnAHsMaOtm5\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763464220892,\"user_tz\":-180,\"elapsed\":4482,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}},\"outputId\":\"1559eb2b-c70a-4369-e379-008676b2ff90\"},\"execution_count\":6,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Collecting hydra-core\\n\",\"  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\\n\",\"Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (2.3.0)\\n\",\"Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core) (4.9.3)\\n\",\"Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from hydra-core) (25.0)\\n\",\"Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf) (6.0.3)\\n\",\"Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\\n\",\"\\u001b[?25l   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m0.0/154.5 kB\\u001b[0m \\u001b[31m?\\u001b[0m eta \\u001b[36m-:--:--\\u001b[0m\\r\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m154.5/154.5 kB\\u001b[0m \\u001b[31m14.1 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\"\\u001b[?25hInstalling collected packages: hydra-core\\n\",\"Successfully installed hydra-core-1.3.2\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"!pip install clearml\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"WOzioQ7gdfYq\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763464232625,\"user_tz\":-180,\"elapsed\":11731,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}},\"outputId\":\"7223695f-4963-418a-c384-fa3f2495701d\"},\"execution_count\":7,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Collecting clearml\\n\",\"  Downloading clearml-2.0.2-py2.py3-none-any.whl.metadata (17 kB)\\n\",\"Requirement already satisfied: attrs>=18.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (25.4.0)\\n\",\"Collecting furl>=2.0.0 (from clearml)\\n\",\"  Downloading furl-2.1.4-py2.py3-none-any.whl.metadata (25 kB)\\n\",\"Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (4.25.1)\\n\",\"Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.0.2)\\n\",\"Collecting pathlib2>=2.3.0 (from clearml)\\n\",\"  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl.metadata (3.5 kB)\\n\",\"Requirement already satisfied: psutil>=3.4.2 in /usr/local/lib/python3.12/dist-packages (from clearml) (5.9.5)\\n\",\"Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from clearml) (3.2.5)\\n\",\"Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.9.0.post0)\\n\",\"Requirement already satisfied: pyjwt<2.11.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.10.1)\\n\",\"Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.12/dist-packages (from clearml) (6.0.3)\\n\",\"Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (1.17.0)\\n\",\"Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.5.0)\\n\",\"Requirement already satisfied: Pillow>=10.3.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (11.3.0)\\n\",\"Requirement already satisfied: referencing<0.40 in /usr/local/lib/python3.12/dist-packages (from clearml) (0.37.0)\\n\",\"Requirement already satisfied: requests>=2.32.0 in /usr/local/lib/python3.12/dist-packages (from clearml) (2.32.4)\\n\",\"Collecting orderedmultidict>=1.0.1 (from furl>=2.0.0->clearml)\\n\",\"  Downloading orderedmultidict-1.0.2-py2.py3-none-any.whl.metadata (1.2 kB)\\n\",\"Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6.0->clearml) (2025.9.1)\\n\",\"Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6.0->clearml) (0.28.0)\\n\",\"Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing<0.40->clearml) (4.15.0)\\n\",\"Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.0->clearml) (3.4.4)\\n\",\"Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.0->clearml) (3.11)\\n\",\"Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.0->clearml) (2025.10.5)\\n\",\"Downloading clearml-2.0.2-py2.py3-none-any.whl (1.2 MB)\\n\",\"\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m1.2/1.2 MB\\u001b[0m \\u001b[31m66.0 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\"\\u001b[?25hDownloading furl-2.1.4-py2.py3-none-any.whl (27 kB)\\n\",\"Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\\n\",\"Downloading orderedmultidict-1.0.2-py2.py3-none-any.whl (11 kB)\\n\",\"Installing collected packages: pathlib2, orderedmultidict, furl, clearml\\n\",\"Successfully installed clearml-2.0.2 furl-2.1.4 orderedmultidict-1.0.2 pathlib2-2.3.7.post1\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"%env CLEARML_WEB_HOST=https://app.clear.ml/\\n\",\"%env CLEARML_API_HOST=https://api.clear.ml\\n\",\"%env CLEARML_FILES_HOST=https://files.clear.ml\\n\",\"%env CLEARML_API_ACCESS_KEY=XGMS61QRIXH7G4URU0X7VGTDAIQUVE\\n\",\"%env CLEARML_API_SECRET_KEY=3mpOB_Br37BLBntBoUvtxmfbBfmkbkdfRUYGje8GfL1gwe_ufJd1w4UzuQWOPaAtTWE\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"hUj8P68pvOai\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763464232638,\"user_tz\":-180,\"elapsed\":10,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}},\"outputId\":\"e36d97c0-e128-4617-d1af-aaa81442e258\"},\"execution_count\":8,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"env: CLEARML_WEB_HOST=https://app.clear.ml/\\n\",\"env: CLEARML_API_HOST=https://api.clear.ml\\n\",\"env: CLEARML_FILES_HOST=https://files.clear.ml\\n\",\"env: CLEARML_API_ACCESS_KEY=XGMS61QRIXH7G4URU0X7VGTDAIQUVE\\n\",\"env: CLEARML_API_SECRET_KEY=3mpOB_Br37BLBntBoUvtxmfbBfmkbkdfRUYGje8GfL1gwe_ufJd1w4UzuQWOPaAtTWE\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"from clearml import Task, Logger\"],\"metadata\":{\"id\":\"6_SELnD-dYv0\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763464241820,\"user_tz\":-180,\"elapsed\":9184,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}}},\"execution_count\":9,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"from google.colab import drive\\n\",\"drive.mount('/content/drive')\\n\",\"\\n\",\"import os\\n\",\"import hydra\\n\",\"from omegaconf import DictConfig, OmegaConf\\n\",\"\\n\",\"config_dir = '/content/drive/MyDrive/segmentation_project/config'\\n\",\"import shutil\\n\",\"if os.path.exists(config_dir):\\n\",\"    shutil.rmtree(config_dir)\\n\",\"\\n\",\"os.makedirs(config_dir, exist_ok=True)\\n\",\"\\n\",\"simple_config = \\\"\\\"\\\"\\n\",\"training:\\n\",\"  batch_size: 16\\n\",\"  epochs: 40\\n\",\"  learning_rate: 0.0002\\n\",\"  optimizer: \\\"AdamW\\\"\\n\",\"  weight_decay: 0.01\\n\",\"\\n\",\"data:\\n\",\"  original_images_dir: \\\"/kaggle/input/abdominalaorta/images\\\"\\n\",\"  original_labels_dir: \\\"/kaggle/input/abdominalaorta/labels\\\"\\n\",\"  output_base_dir: \\\"/content/base_patients\\\"\\n\",\"  test_size: 0.2\\n\",\"  random_state: 42\\n\",\"  image_size: 256\\n\",\"  num_workers: 2\\n\",\"\\n\",\"model:\\n\",\"  in_channel: 1\\n\",\"  out_channel: 2\\n\",\"\\n\",\"transforms:\\n\",\"  image_size: 256\\n\",\"\\\"\\\"\\\"\\n\",\"\\n\",\"with open(f'{config_dir}/config.yaml', 'w') as f:\\n\",\"    f.write(simple_config)\\n\",\"\\n\",\"def load_hydra_config():\\n\",\"    config_path = \\\"/content/drive/MyDrive/segmentation_project/config\\\"\\n\",\"    config_name = \\\"config\\\"\\n\",\"\\n\",\"    with hydra.initialize_config_dir(config_dir=config_path, version_base=\\\"1.2\\\"):\\n\",\"        cfg = hydra.compose(config_name=config_name)\\n\",\"\\n\",\"    OmegaConf.set_struct(cfg, False)\\n\",\"\\n\",\"    return cfg\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"I3J-8nzvrbqu\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763464381159,\"user_tz\":-180,\"elapsed\":2372,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}},\"outputId\":\"d7e753cc-30e3-4cfe-ac2f-ee270dc2230b\"},\"execution_count\":19,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\\\"/content/drive\\\", force_remount=True).\\n\",\"✅ Простой конфиг создан!\\n\"]}]},{\"cell_type\":\"markdown\",\"source\":[\"Разделение на train test выборку по пациентам\"],\"metadata\":{\"id\":\"DxpjPceMJe3L\"}},{\"cell_type\":\"code\",\"source\":[\"def create_train_test_split_by_patient():\\n\",\"    cfg = load_hydra_config()\\n\",\"    patient_folders = []\\n\",\"    for folder in os.listdir(cfg.data.original_images_dir):\\n\",\"        folder_path = os.path.join(cfg.data.original_images_dir, folder)\\n\",\"        if (os.path.isdir(folder_path) and\\n\",\"            os.path.exists(os.path.join(cfg.data.original_labels_dir, folder))):\\n\",\"            patient_folders.append(folder)\\n\",\"\\n\",\"    train_patients, test_patients = train_test_split(\\n\",\"        patient_folders,\\n\",\"        test_size=cfg.data.test_size,\\n\",\"        random_state=cfg.data.random_state\\n\",\"    )\\n\",\"\\n\",\"    train_images_dir = os.path.join(cfg.data.output_base_dir, 'train', 'images')\\n\",\"    train_labels_dir = os.path.join(cfg.data.output_base_dir, 'train', 'labels')\\n\",\"    test_images_dir = os.path.join(cfg.data.output_base_dir, 'test', 'images')\\n\",\"    test_labels_dir = os.path.join(cfg.data.output_base_dir, 'test', 'labels')\\n\",\"\\n\",\"    for dir_path in [train_images_dir, train_labels_dir, test_images_dir, test_labels_dir]:\\n\",\"        os.makedirs(dir_path, exist_ok=True)\\n\",\"\\n\",\"    def copy_patient_files(patients, src_images_dir, src_labels_dir, dst_images_dir, dst_labels_dir):\\n\",\"        total_files = 0\\n\",\"        for patient in patients:\\n\",\"            patient_images_dir = os.path.join(src_images_dir, patient)\\n\",\"            patient_labels_dir = os.path.join(src_labels_dir, patient)\\n\",\"\\n\",\"            for file in os.listdir(patient_images_dir):\\n\",\"                if file.endswith('.png'):\\n\",\"                    src_image_path = os.path.join(patient_images_dir, file)\\n\",\"                    dst_image_path = os.path.join(dst_images_dir, f\\\"{patient}_{file}\\\")\\n\",\"                    shutil.copy2(src_image_path, dst_image_path)\\n\",\"\\n\",\"                    src_label_path = os.path.join(patient_labels_dir, file)\\n\",\"                    dst_label_path = os.path.join(dst_labels_dir, f\\\"{patient}_{file}\\\")\\n\",\"                    shutil.copy2(src_label_path, dst_label_path)\\n\",\"\\n\",\"                    total_files += 1\\n\",\"\\n\",\"        return total_files\\n\",\"\\n\",\"    train_total = copy_patient_files(train_patients, cfg.data.original_images_dir, cfg.data.original_labels_dir,\\n\",\"                                   train_images_dir, train_labels_dir)\\n\",\"\\n\",\"    test_total = copy_patient_files(test_patients, cfg.data.original_images_dir, cfg.data.original_labels_dir,\\n\",\"                                  test_images_dir, test_labels_dir)\\n\",\"\\n\",\"    return {\\n\",\"        'train_images': train_images_dir,\\n\",\"        'train_labels': train_labels_dir,\\n\",\"        'test_images': test_images_dir,\\n\",\"        'test_labels': test_labels_dir,\\n\",\"        'train_patients': train_patients,\\n\",\"        'test_patients': test_patients\\n\",\"    }\"],\"metadata\":{\"trusted\":true,\"execution\":{\"iopub.status.busy\":\"2025-11-15T07:29:38.174796Z\",\"iopub.execute_input\":\"2025-11-15T07:29:38.175296Z\",\"iopub.status.idle\":\"2025-11-15T07:29:38.187116Z\",\"shell.execute_reply.started\":\"2025-11-15T07:29:38.175273Z\",\"shell.execute_reply\":\"2025-11-15T07:29:38.186273Z\"},\"id\":\"zNBbqzptObnZ\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763464382924,\"user_tz\":-180,\"elapsed\":4,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}}},\"outputs\":[],\"execution_count\":20},{\"cell_type\":\"markdown\",\"source\":[\"Датасет\"],\"metadata\":{\"id\":\"ohC3O2TgJoZ7\"}},{\"cell_type\":\"code\",\"source\":[\"class SegmentationDataset(Dataset):\\n\",\"    def __init__(self, images_dir, labels_dir, transform=None):\\n\",\"        self.images_dir = images_dir\\n\",\"        self.labels_dir = labels_dir\\n\",\"        self.transform = transform\\n\",\"\\n\",\"        self.image_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.png')])\\n\",\"        self.label_files = sorted([f for f in os.listdir(labels_dir) if f.endswith('.png')])\\n\",\"    def __len__(self):\\n\",\"        return len(self.image_files)\\n\",\"\\n\",\"    def __getitem__(self, idx):\\n\",\"        image_path = os.path.join(self.images_dir, self.image_files[idx])\\n\",\"        label_path = os.path.join(self.labels_dir, self.label_files[idx])\\n\",\"        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\\n\",\"        label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\\n\",\"\\n\",\"        if self.transform:\\n\",\"            transformed = self.transform(image=image, mask=label)\\n\",\"            image = transformed['image']\\n\",\"            label = transformed['mask']\\n\",\"        label = (label > 0).long()\\n\",\"\\n\",\"        return image, label\"],\"metadata\":{\"trusted\":true,\"execution\":{\"iopub.status.busy\":\"2025-11-15T07:29:38.188095Z\",\"iopub.execute_input\":\"2025-11-15T07:29:38.188463Z\",\"iopub.status.idle\":\"2025-11-15T07:29:38.256584Z\",\"shell.execute_reply.started\":\"2025-11-15T07:29:38.188439Z\",\"shell.execute_reply\":\"2025-11-15T07:29:38.255572Z\"},\"id\":\"yycXtF2gObnZ\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763464384928,\"user_tz\":-180,\"elapsed\":74,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}}},\"outputs\":[],\"execution_count\":21},{\"cell_type\":\"markdown\",\"source\":[\"Модель Unet\"],\"metadata\":{\"id\":\"8NpnAj2lJw2h\"}},{\"cell_type\":\"code\",\"source\":[\"import torch\\n\",\"import torch.nn as nn\\n\",\"import torch.nn.functional as F\\n\",\"\\n\",\"class UNet(nn.Module):\\n\",\"    def contracting_block(self, in_channels, out_channels, kernel_size=3):\\n\",\"        block = torch.nn.Sequential(\\n\",\"            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=1),\\n\",\"            torch.nn.ReLU(),\\n\",\"            torch.nn.BatchNorm2d(out_channels),\\n\",\"            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels, padding=1),\\n\",\"            torch.nn.ReLU(),\\n\",\"            torch.nn.BatchNorm2d(out_channels),\\n\",\"        )\\n\",\"        return block\\n\",\"\\n\",\"    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\\n\",\"        block = torch.nn.Sequential(\\n\",\"            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\\n\",\"            torch.nn.ReLU(),\\n\",\"            torch.nn.BatchNorm2d(mid_channel),\\n\",\"            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\\n\",\"            torch.nn.ReLU(),\\n\",\"            torch.nn.BatchNorm2d(mid_channel),\\n\",\"            torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=2, stride=2)\\n\",\"        )\\n\",\"        return block\\n\",\"\\n\",\"    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\\n\",\"        block = torch.nn.Sequential(\\n\",\"            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\\n\",\"            torch.nn.ReLU(),\\n\",\"            torch.nn.BatchNorm2d(mid_channel),\\n\",\"            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\\n\",\"            torch.nn.ReLU(),\\n\",\"            torch.nn.BatchNorm2d(mid_channel),\\n\",\"            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\\n\",\"        )\\n\",\"        return block\\n\",\"\\n\",\"    def __init__(self, in_channel, out_channel):\\n\",\"        super(UNet, self).__init__()\\n\",\"        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\\n\",\"        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\\n\",\"        self.conv_encode2 = self.contracting_block(64, 128)\\n\",\"        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\\n\",\"        self.conv_encode3 = self.contracting_block(128, 256)\\n\",\"        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\\n\",\"\\n\",\"        self.bottleneck = torch.nn.Sequential(\\n\",\"            torch.nn.Conv2d(kernel_size=3, in_channels=256, out_channels=512, padding=1),\\n\",\"            torch.nn.ReLU(),\\n\",\"            torch.nn.BatchNorm2d(512),\\n\",\"            torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512, padding=1),\\n\",\"            torch.nn.ReLU(),\\n\",\"            torch.nn.BatchNorm2d(512),\\n\",\"            torch.nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2)\\n\",\"        )\\n\",\"\\n\",\"        self.conv_decode3 = self.expansive_block(512, 256, 128)\\n\",\"        self.conv_decode2 = self.expansive_block(256, 128, 64)\\n\",\"        self.final_layer = self.final_block(128, 64, out_channel)\\n\",\"\\n\",\"    def crop_and_concat(self, upsampled, bypass):\\n\",\"        _, _, h_up, w_up = upsampled.size()\\n\",\"        _, _, h_by, w_by = bypass.size()\\n\",\"\\n\",\"        crop_h = (h_by - h_up) // 2\\n\",\"        crop_w = (w_by - w_up) // 2\\n\",\"\\n\",\"        bypass_cropped = bypass[:, :,\\n\",\"                              crop_h:crop_h + h_up,\\n\",\"                              crop_w:crop_w + w_up]\\n\",\"\\n\",\"        return torch.cat((upsampled, bypass_cropped), 1)\\n\",\"\\n\",\"    def forward(self, x):\\n\",\"        encode_block1 = self.conv_encode1(x)\\n\",\"        encode_pool1 = self.conv_maxpool1(encode_block1)\\n\",\"\\n\",\"        encode_block2 = self.conv_encode2(encode_pool1)\\n\",\"        encode_pool2 = self.conv_maxpool2(encode_block2)\\n\",\"\\n\",\"        encode_block3 = self.conv_encode3(encode_pool2)\\n\",\"        encode_pool3 = self.conv_maxpool3(encode_block3)\\n\",\"\\n\",\"        bottleneck1 = self.bottleneck(encode_pool3)\\n\",\"\\n\",\"        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3)\\n\",\"        cat_layer2 = self.conv_decode3(decode_block3)\\n\",\"\\n\",\"        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2)\\n\",\"        cat_layer1 = self.conv_decode2(decode_block2)\\n\",\"\\n\",\"        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1)\\n\",\"        final_layer = self.final_layer(decode_block1)\\n\",\"\\n\",\"        return final_layer\"],\"metadata\":{\"trusted\":true,\"execution\":{\"iopub.status.busy\":\"2025-11-15T07:29:38.257612Z\",\"iopub.execute_input\":\"2025-11-15T07:29:38.257905Z\",\"iopub.status.idle\":\"2025-11-15T07:29:38.280443Z\",\"shell.execute_reply.started\":\"2025-11-15T07:29:38.257873Z\",\"shell.execute_reply\":\"2025-11-15T07:29:38.279547Z\"},\"id\":\"U7O5qetOObna\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763464386272,\"user_tz\":-180,\"elapsed\":10,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}}},\"outputs\":[],\"execution_count\":22},{\"cell_type\":\"markdown\",\"source\":[\"Аугментация и предподготовка\"],\"metadata\":{\"id\":\"g5YUhSiGJ0tL\"}},{\"cell_type\":\"code\",\"source\":[\"import albumentations as A\\n\",\"from albumentations.pytorch import ToTensorV2\\n\",\"import cv2\\n\",\"\\n\",\"def transformers():\\n\",\"    cfg = load_hydra_config()\\n\",\"    train_transform = A.Compose([\\n\",\"        A.Resize(height=cfg.transforms.image_size, width=cfg.transforms.image_size),\\n\",\"\\n\",\"        A.HorizontalFlip(p=0.5),\\n\",\"        A.VerticalFlip(p=0.3),\\n\",\"        A.RandomRotate90(p=0.5),\\n\",\"        A.Affine(\\n\",\"            translate_percent={'x': (-0.05, 0.05), 'y': (-0.05, 0.05)},\\n\",\"            scale=(0.9, 1.1),\\n\",\"            rotate=(-10, 10),\\n\",\"            p=0.5\\n\",\"        ),\\n\",\"        A.RandomBrightnessContrast(\\n\",\"            brightness_limit=0.1,\\n\",\"            contrast_limit=0.1,\\n\",\"            p=0.3\\n\",\"        ),\\n\",\"        A.GaussNoise(var_limit=(10.0, 30.0), p=0.2),\\n\",\"\\n\",\"        A.Normalize(mean=[0.5], std=[0.5]),\\n\",\"        ToTensorV2(),\\n\",\"    ])\\n\",\"\\n\",\"    val_transform = A.Compose([\\n\",\"        A.Resize(height=cfg.transforms.image_size, width=cfg.transforms.image_size),\\n\",\"        A.Normalize(mean=[0.5], std=[0.5]),\\n\",\"        ToTensorV2(),\\n\",\"    ])\\n\",\"\\n\",\"    return train_transform, val_transform\"],\"metadata\":{\"trusted\":true,\"execution\":{\"iopub.status.busy\":\"2025-11-15T07:29:38.283090Z\",\"iopub.execute_input\":\"2025-11-15T07:29:38.283404Z\",\"iopub.status.idle\":\"2025-11-15T07:29:39.509192Z\",\"shell.execute_reply.started\":\"2025-11-15T07:29:38.283347Z\",\"shell.execute_reply\":\"2025-11-15T07:29:39.508032Z\"},\"id\":\"oaDmNuPsObna\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763464388362,\"user_tz\":-180,\"elapsed\":39,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}}},\"outputs\":[],\"execution_count\":23},{\"cell_type\":\"code\",\"source\":[\"!pip install torchmetrics\\n\",\"from torchmetrics.segmentation import DiceScore\\n\",\"from torchmetrics import JaccardIndex\\n\",\"from torchmetrics import Precision, Recall\\n\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"qiuvASFAgnXF\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763465405729,\"user_tz\":-180,\"elapsed\":7107,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}},\"outputId\":\"9c530985-f39f-47ba-b4a4-882021e37610\"},\"execution_count\":30,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\\n\",\"Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\\n\",\"Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\\n\",\"Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\\n\",\"Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\\n\",\"Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\\n\",\"Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\\n\",\"Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\\n\",\"Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\\n\",\"Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\\n\",\"Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\\n\",\"Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\\n\",\"Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\\n\",\"Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\\n\",\"Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\\n\",\"Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\\n\",\"Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\\n\",\"Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\\n\",\"Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\\n\",\"Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\\n\",\"Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\\n\",\"Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\\n\",\"Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\\n\",\"Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\\n\",\"Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\\n\",\"Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\\n\",\"Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\\n\",\"Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\\n\",\"Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"def train_model():\\n\",\"    cfg = load_hydra_config()\\n\",\"    task = Task.init(\\n\",\"        project_name=\\\"MedicalSegmentation\\\",\\n\",\"        task_name=f\\\"UNet_{cfg.training.epochs}epochs\\\",\\n\",\"        auto_connect_frameworks={'pytorch': True, 'hydra': True}\\n\",\"    )\\n\",\"    cfg_dict = OmegaConf.to_container(cfg, resolve=True)\\n\",\"    task.connect_configuration(cfg_dict)\\n\",\"    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n\",\"    paths = create_train_test_split_by_patient()\\n\",\"    train_transform, val_transform = transformers()\\n\",\"    train_dataset = SegmentationDataset(\\n\",\"        images_dir=paths['train_images'],\\n\",\"        labels_dir=paths['train_labels'],\\n\",\"        transform=train_transform\\n\",\"    )\\n\",\"\\n\",\"    test_dataset = SegmentationDataset(\\n\",\"        images_dir=paths['test_images'],\\n\",\"        labels_dir=paths['test_labels'],\\n\",\"        transform=val_transform\\n\",\"    )\\n\",\"    train_loader = DataLoader(\\n\",\"        train_dataset,\\n\",\"        batch_size=cfg.training.batch_size,\\n\",\"        shuffle=True,\\n\",\"        num_workers=cfg.data.num_workers\\n\",\"    )\\n\",\"\\n\",\"    test_loader = DataLoader(\\n\",\"        test_dataset,\\n\",\"        batch_size=cfg.training.batch_size,\\n\",\"        shuffle=False,\\n\",\"        num_workers=cfg.data.num_workers\\n\",\"    )\\n\",\"\\n\",\"    model = UNet(cfg.model.in_channel, cfg.model.out_channel).to(device)\\n\",\"\\n\",\"    criterion = nn.CrossEntropyLoss()\\n\",\"    optimizer = torch.optim.AdamW(\\n\",\"        model.parameters(),\\n\",\"        lr=cfg.training.learning_rate,\\n\",\"        weight_decay=cfg.training.weight_decay\\n\",\"    )\\n\",\"    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\\n\",\"    dice_metric = DiceScore(num_classes=2, average='macro', input_format='index').to(device)\\n\",\"    iou_metric = JaccardIndex(num_classes=2, task='multiclass', average='macro').to(device)\\n\",\"    precision_metric = Precision(num_classes=2, task='multiclass',average='macro').to(device)\\n\",\"    recall_metric = Recall(num_classes=2, task='multiclass',average='macro').to(device)\\n\",\"\\n\",\"    train_losses = []\\n\",\"    val_dice_scores = []\\n\",\"    val_iou_scores = []\\n\",\"    val_pres_scores = []\\n\",\"    val_rec_scores = []\\n\",\"    best_dice = 0\\n\",\"    best_epoch = 0\\n\",\"    for epoch in range(cfg.training.epochs):\\n\",\"        model.train()\\n\",\"        epoch_train_loss = 0\\n\",\"        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch}/{cfg.training.epochs} [Train]')\\n\",\"\\n\",\"        for idx, (images, labels) in enumerate(train_pbar):\\n\",\"            images, labels = images.to(device), labels.to(device)\\n\",\"            labels = labels.long()\\n\",\"            optimizer.zero_grad()\\n\",\"            output = model(images)\\n\",\"            loss = criterion(output, labels)\\n\",\"            loss.backward()\\n\",\"            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\\n\",\"            optimizer.step()\\n\",\"            epoch_train_loss += loss.item()\\n\",\"\\n\",\"            train_pbar.set_postfix({\\n\",\"                'Loss': f'{loss.item():.4f}',\\n\",\"                'Avg Loss': f'{epoch_train_loss/(idx+1):.4f}'\\n\",\"            })\\n\",\"\\n\",\"        train_pbar.close()\\n\",\"        avg_train_loss = epoch_train_loss / len(train_loader)\\n\",\"\\n\",\"        model.eval()\\n\",\"        epoch_val_dice = 0\\n\",\"        val_batches = 0\\n\",\"        val_pbar = tqdm(test_loader, desc=f'Epoch {epoch+1}/{cfg.training.epochs} [Val]')\\n\",\"\\n\",\"\\n\",\"        dice_metric.reset()\\n\",\"        iou_metric.reset()\\n\",\"        precision_metric.reset()\\n\",\"        recall_metric.reset()\\n\",\"\\n\",\"        with torch.no_grad():\\n\",\"            for idx, (images, masks) in enumerate(val_pbar):\\n\",\"                images, masks = images.to(device), masks.to(device)\\n\",\"                masks = masks.long()\\n\",\"                outputs = model(images)\\n\",\"                probs = torch.softmax(outputs, dim=1)\\n\",\"                preds = torch.argmax(probs, dim=1)\\n\",\"\\n\",\"                dice_metric.update(preds, masks)\\n\",\"                iou_metric.update(preds, masks)\\n\",\"                precision_metric.update(preds, masks)\\n\",\"                recall_metric.update(preds, masks)\\n\",\"\\n\",\"                val_batches += 1\\n\",\"\\n\",\"                val_pbar.set_postfix({\\n\",\"                    'Avg Dice': f'{epoch_val_dice/val_batches:.4f}'\\n\",\"                })\\n\",\"\\n\",\"        val_pbar.close()\\n\",\"        avg_val_dice = dice_metric.compute()\\n\",\"        avg_val_iou = iou_metric.compute()\\n\",\"        avg_val_pres = precision_metric.compute()\\n\",\"        avg_val_rec = recall_metric.compute()\\n\",\"        if avg_val_dice > best_dice:\\n\",\"            best_dice = avg_val_dice.item()\\n\",\"            best_epoch = epoch\\n\",\"            torch.save({\\n\",\"                'epoch': epoch,\\n\",\"                'model_state_dict': model.state_dict(),\\n\",\"                'optimizer_state_dict': optimizer.state_dict(),\\n\",\"                'scheduler_state_dict': scheduler.state_dict(),\\n\",\"                'dice_score': best_dice,\\n\",\"                'iou_score': avg_val_iou.item(),\\n\",\"                'loss': avg_train_loss,\\n\",\"            }, 'best_model.pth')\\n\",\"\\n\",\"        logger = Logger.current_logger()\\n\",\"        logger.report_scalar(\\\"Loss\\\", \\\"Train\\\", avg_train_loss, epoch)\\n\",\"        logger.report_scalar(\\\"Metrics\\\", \\\"Dice\\\", avg_val_dice.item(), epoch)\\n\",\"        logger.report_scalar(\\\"Metrics\\\", \\\"Iou\\\", avg_val_iou.item(), epoch)\\n\",\"        logger.report_scalar(\\\"Metrics\\\", \\\"Precision\\\", avg_val_pres.item(), epoch)\\n\",\"        logger.report_scalar(\\\"Metrics\\\", \\\"Recall\\\", avg_val_rec.item(), epoch)\\n\",\"\\n\",\"        train_losses.append(avg_train_loss)\\n\",\"        val_dice_scores.append(avg_val_dice.item())\\n\",\"        val_iou_scores.append(avg_val_iou.item())\\n\",\"        val_pres_scores.append(avg_val_pres.item())\\n\",\"        val_rec_scores.append(avg_val_rec.item())\\n\",\"\\n\",\"        scheduler.step(avg_train_loss)\\n\",\"\\n\",\"        print(f'Epoch {epoch:03d}:')\\n\",\"        print(f'  Loss: {avg_train_loss:.4f}')\\n\",\"        print(f'  Dice: {avg_val_dice.item():.4f}')\\n\",\"        print(f'  Iou: {avg_val_iou.item():.4f}')\\n\",\"        print(f'  Precision: {avg_val_pres.item():.4f}')\\n\",\"        print(f'  Recall: {avg_val_rec.item():.4f}')\\n\",\"        print(f'  LR:   {optimizer.param_groups[0][\\\"lr\\\"]:.2e}')\\n\",\"        print(f'Best Dice {best_dice:.4f} Epoch {best_epoch}')\\n\",\"        print('-' * 40)\"],\"metadata\":{\"id\":\"cwiGIXNmu0Hs\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763474755898,\"user_tz\":-180,\"elapsed\":17,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}}},\"execution_count\":35,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"if __name__ == \\\"__main__\\\":\\n\",\"    results = train_model()\"],\"metadata\":{\"trusted\":true,\"execution\":{\"iopub.status.busy\":\"2025-11-15T07:30:15.340811Z\",\"iopub.execute_input\":\"2025-11-15T07:30:15.341141Z\",\"execution_failed\":\"2025-11-15T10:47:36.006Z\"},\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"8o6KyklqObnb\",\"outputId\":\"e26f3ece-4805-4380-87a6-b79cbf15929e\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763473841169,\"user_tz\":-180,\"elapsed\":8259180,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}}},\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"/tmp/ipython-input-624610810.py:24: UserWarning:\\n\",\"\\n\",\"Argument(s) 'var_limit' are not valid for transform GaussNoise\\n\",\"\\n\",\"Epoch 0/40 [Train]: 100%|██████████| 250/250 [03:10<00:00,  1.31it/s, Loss=0.0788, Avg Loss=0.3137]\\n\",\"Epoch 1/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.57it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 000:\\n\",\"  Loss: 0.3137\\n\",\"  Dice: 0.4983\\n\",\"  Iou: 0.4965\\n\",\"  Precision: 0.4965\\n\",\"  Recall: 0.5000\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 1/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.33it/s, Loss=0.0308, Avg Loss=0.0410]\\n\",\"Epoch 2/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.43it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 001:\\n\",\"  Loss: 0.0410\\n\",\"  Dice: 0.8745\\n\",\"  Iou: 0.8261\\n\",\"  Precision: 0.8697\\n\",\"  Recall: 0.9244\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 2/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.33it/s, Loss=0.0176, Avg Loss=0.0172]\\n\",\"Epoch 3/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.57it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 002:\\n\",\"  Loss: 0.0172\\n\",\"  Dice: 0.8821\\n\",\"  Iou: 0.8567\\n\",\"  Precision: 0.9246\\n\",\"  Recall: 0.9089\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 3/40 [Train]: 100%|██████████| 250/250 [03:08<00:00,  1.33it/s, Loss=0.0109, Avg Loss=0.0116]\\n\",\"Epoch 4/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.40it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 003:\\n\",\"  Loss: 0.0116\\n\",\"  Dice: 0.9149\\n\",\"  Iou: 0.8811\\n\",\"  Precision: 0.9299\\n\",\"  Recall: 0.9355\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 4/40 [Train]: 100%|██████████| 250/250 [03:08<00:00,  1.32it/s, Loss=0.0133, Avg Loss=0.0090]\\n\",\"Epoch 5/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.60it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 004:\\n\",\"  Loss: 0.0090\\n\",\"  Dice: 0.9408\\n\",\"  Iou: 0.9221\\n\",\"  Precision: 0.9622\\n\",\"  Recall: 0.9535\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 5/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.33it/s, Loss=0.0098, Avg Loss=0.0075]\\n\",\"Epoch 6/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.50it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 005:\\n\",\"  Loss: 0.0075\\n\",\"  Dice: 0.9372\\n\",\"  Iou: 0.9148\\n\",\"  Precision: 0.9622\\n\",\"  Recall: 0.9451\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 6/40 [Train]: 100%|██████████| 250/250 [03:08<00:00,  1.33it/s, Loss=0.0068, Avg Loss=0.0070]\\n\",\"Epoch 7/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.44it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 006:\\n\",\"  Loss: 0.0070\\n\",\"  Dice: 0.9343\\n\",\"  Iou: 0.9146\\n\",\"  Precision: 0.9657\\n\",\"  Recall: 0.9417\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 7/40 [Train]: 100%|██████████| 250/250 [03:08<00:00,  1.33it/s, Loss=0.0083, Avg Loss=0.0063]\\n\",\"Epoch 8/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.63it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 007:\\n\",\"  Loss: 0.0063\\n\",\"  Dice: 0.9377\\n\",\"  Iou: 0.9169\\n\",\"  Precision: 0.9517\\n\",\"  Recall: 0.9579\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 8/40 [Train]: 100%|██████████| 250/250 [03:06<00:00,  1.34it/s, Loss=0.0101, Avg Loss=0.0058]\\n\",\"Epoch 9/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.40it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 008:\\n\",\"  Loss: 0.0058\\n\",\"  Dice: 0.9417\\n\",\"  Iou: 0.9194\\n\",\"  Precision: 0.9655\\n\",\"  Recall: 0.9474\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 9/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.33it/s, Loss=0.0096, Avg Loss=0.0056]\\n\",\"Epoch 10/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.58it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 009:\\n\",\"  Loss: 0.0056\\n\",\"  Dice: 0.9413\\n\",\"  Iou: 0.9213\\n\",\"  Precision: 0.9405\\n\",\"  Recall: 0.9756\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 10/40 [Train]: 100%|██████████| 250/250 [03:08<00:00,  1.32it/s, Loss=0.0069, Avg Loss=0.0053]\\n\",\"Epoch 11/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.37it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 010:\\n\",\"  Loss: 0.0053\\n\",\"  Dice: 0.9500\\n\",\"  Iou: 0.9299\\n\",\"  Precision: 0.9659\\n\",\"  Recall: 0.9588\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 11/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.33it/s, Loss=0.0081, Avg Loss=0.0050]\\n\",\"Epoch 12/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.55it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 011:\\n\",\"  Loss: 0.0050\\n\",\"  Dice: 0.9555\\n\",\"  Iou: 0.9385\\n\",\"  Precision: 0.9772\\n\",\"  Recall: 0.9577\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 12/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.33it/s, Loss=0.0054, Avg Loss=0.0049]\\n\",\"Epoch 13/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.35it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 012:\\n\",\"  Loss: 0.0049\\n\",\"  Dice: 0.9493\\n\",\"  Iou: 0.9287\\n\",\"  Precision: 0.9572\\n\",\"  Recall: 0.9662\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 13/40 [Train]: 100%|██████████| 250/250 [03:08<00:00,  1.33it/s, Loss=0.0063, Avg Loss=0.0047]\\n\",\"Epoch 14/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.38it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 013:\\n\",\"  Loss: 0.0047\\n\",\"  Dice: 0.9479\\n\",\"  Iou: 0.9319\\n\",\"  Precision: 0.9685\\n\",\"  Recall: 0.9586\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 14/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.34it/s, Loss=0.0078, Avg Loss=0.0047]\\n\",\"Epoch 15/40 [Val]: 100%|██████████| 63/63 [00:19<00:00,  3.26it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 014:\\n\",\"  Loss: 0.0047\\n\",\"  Dice: 0.9492\\n\",\"  Iou: 0.9310\\n\",\"  Precision: 0.9708\\n\",\"  Recall: 0.9554\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 15/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.33it/s, Loss=0.0056, Avg Loss=0.0043]\\n\",\"Epoch 16/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.51it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 015:\\n\",\"  Loss: 0.0043\\n\",\"  Dice: 0.9531\\n\",\"  Iou: 0.9334\\n\",\"  Precision: 0.9693\\n\",\"  Recall: 0.9595\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 16/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.34it/s, Loss=0.0072, Avg Loss=0.0044]\\n\",\"Epoch 17/40 [Val]: 100%|██████████| 63/63 [00:19<00:00,  3.21it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 016:\\n\",\"  Loss: 0.0044\\n\",\"  Dice: 0.9559\\n\",\"  Iou: 0.9392\\n\",\"  Precision: 0.9752\\n\",\"  Recall: 0.9603\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 17/40 [Train]: 100%|██████████| 250/250 [03:06<00:00,  1.34it/s, Loss=0.0052, Avg Loss=0.0044]\\n\",\"Epoch 18/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.56it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 017:\\n\",\"  Loss: 0.0044\\n\",\"  Dice: 0.9539\\n\",\"  Iou: 0.9342\\n\",\"  Precision: 0.9627\\n\",\"  Recall: 0.9670\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 18/40 [Train]: 100%|██████████| 250/250 [03:08<00:00,  1.33it/s, Loss=0.0075, Avg Loss=0.0043]\\n\",\"Epoch 19/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.35it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 018:\\n\",\"  Loss: 0.0043\\n\",\"  Dice: 0.9566\\n\",\"  Iou: 0.9399\\n\",\"  Precision: 0.9662\\n\",\"  Recall: 0.9699\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 19/40 [Train]: 100%|██████████| 250/250 [03:08<00:00,  1.33it/s, Loss=0.0064, Avg Loss=0.0040]\\n\",\"Epoch 20/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.57it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 019:\\n\",\"  Loss: 0.0040\\n\",\"  Dice: 0.9581\\n\",\"  Iou: 0.9415\\n\",\"  Precision: 0.9668\\n\",\"  Recall: 0.9712\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 20/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.34it/s, Loss=0.0074, Avg Loss=0.0041]\\n\",\"Epoch 21/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.34it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 020:\\n\",\"  Loss: 0.0041\\n\",\"  Dice: 0.9592\\n\",\"  Iou: 0.9400\\n\",\"  Precision: 0.9698\\n\",\"  Recall: 0.9664\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 21/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.33it/s, Loss=0.0060, Avg Loss=0.0041]\\n\",\"Epoch 22/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.57it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 021:\\n\",\"  Loss: 0.0041\\n\",\"  Dice: 0.9577\\n\",\"  Iou: 0.9426\\n\",\"  Precision: 0.9730\\n\",\"  Recall: 0.9663\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 22/40 [Train]: 100%|██████████| 250/250 [03:08<00:00,  1.33it/s, Loss=0.0060, Avg Loss=0.0040]\\n\",\"Epoch 23/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.34it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 022:\\n\",\"  Loss: 0.0040\\n\",\"  Dice: 0.9465\\n\",\"  Iou: 0.9312\\n\",\"  Precision: 0.9741\\n\",\"  Recall: 0.9526\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 23/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.34it/s, Loss=0.0060, Avg Loss=0.0039]\\n\",\"Epoch 24/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.60it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 023:\\n\",\"  Loss: 0.0039\\n\",\"  Dice: 0.9591\\n\",\"  Iou: 0.9455\\n\",\"  Precision: 0.9647\\n\",\"  Recall: 0.9779\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 24/40 [Train]: 100%|██████████| 250/250 [03:08<00:00,  1.33it/s, Loss=0.0073, Avg Loss=0.0038]\\n\",\"Epoch 25/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.35it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 024:\\n\",\"  Loss: 0.0038\\n\",\"  Dice: 0.9623\\n\",\"  Iou: 0.9469\\n\",\"  Precision: 0.9728\\n\",\"  Recall: 0.9711\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 25/40 [Train]: 100%|██████████| 250/250 [03:08<00:00,  1.33it/s, Loss=0.0063, Avg Loss=0.0038]\\n\",\"Epoch 26/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.52it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 025:\\n\",\"  Loss: 0.0038\\n\",\"  Dice: 0.9531\\n\",\"  Iou: 0.9397\\n\",\"  Precision: 0.9683\\n\",\"  Recall: 0.9675\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 26/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.33it/s, Loss=0.0058, Avg Loss=0.0038]\\n\",\"Epoch 27/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.43it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 026:\\n\",\"  Loss: 0.0038\\n\",\"  Dice: 0.9549\\n\",\"  Iou: 0.9412\\n\",\"  Precision: 0.9696\\n\",\"  Recall: 0.9680\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 27/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.33it/s, Loss=0.0055, Avg Loss=0.0038]\\n\",\"Epoch 28/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.56it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 027:\\n\",\"  Loss: 0.0038\\n\",\"  Dice: 0.9579\\n\",\"  Iou: 0.9431\\n\",\"  Precision: 0.9615\\n\",\"  Recall: 0.9785\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 28/40 [Train]: 100%|██████████| 250/250 [03:08<00:00,  1.32it/s, Loss=0.0060, Avg Loss=0.0038]\\n\",\"Epoch 29/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.48it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 028:\\n\",\"  Loss: 0.0038\\n\",\"  Dice: 0.9603\\n\",\"  Iou: 0.9435\\n\",\"  Precision: 0.9727\\n\",\"  Recall: 0.9675\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 29/40 [Train]: 100%|██████████| 250/250 [03:06<00:00,  1.34it/s, Loss=0.0075, Avg Loss=0.0036]\\n\",\"Epoch 30/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.56it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 029:\\n\",\"  Loss: 0.0036\\n\",\"  Dice: 0.9597\\n\",\"  Iou: 0.9454\\n\",\"  Precision: 0.9667\\n\",\"  Recall: 0.9756\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 30/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.33it/s, Loss=0.0055, Avg Loss=0.0037]\\n\",\"Epoch 31/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.34it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 030:\\n\",\"  Loss: 0.0037\\n\",\"  Dice: 0.9543\\n\",\"  Iou: 0.9384\\n\",\"  Precision: 0.9652\\n\",\"  Recall: 0.9692\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 31/40 [Train]: 100%|██████████| 250/250 [03:06<00:00,  1.34it/s, Loss=0.0046, Avg Loss=0.0035]\\n\",\"Epoch 32/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.60it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 031:\\n\",\"  Loss: 0.0035\\n\",\"  Dice: 0.9609\\n\",\"  Iou: 0.9452\\n\",\"  Precision: 0.9707\\n\",\"  Recall: 0.9713\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 32/40 [Train]: 100%|██████████| 250/250 [03:06<00:00,  1.34it/s, Loss=0.0036, Avg Loss=0.0036]\\n\",\"Epoch 33/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.43it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 032:\\n\",\"  Loss: 0.0036\\n\",\"  Dice: 0.9619\\n\",\"  Iou: 0.9462\\n\",\"  Precision: 0.9761\\n\",\"  Recall: 0.9672\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 33/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.34it/s, Loss=0.0034, Avg Loss=0.0034]\\n\",\"Epoch 34/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.57it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 033:\\n\",\"  Loss: 0.0034\\n\",\"  Dice: 0.9628\\n\",\"  Iou: 0.9472\\n\",\"  Precision: 0.9776\\n\",\"  Recall: 0.9668\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 34/40 [Train]: 100%|██████████| 250/250 [03:06<00:00,  1.34it/s, Loss=0.0047, Avg Loss=0.0033]\\n\",\"Epoch 35/40 [Val]: 100%|██████████| 63/63 [00:19<00:00,  3.23it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 034:\\n\",\"  Loss: 0.0033\\n\",\"  Dice: 0.9529\\n\",\"  Iou: 0.9393\\n\",\"  Precision: 0.9637\\n\",\"  Recall: 0.9718\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 35/40 [Train]: 100%|██████████| 250/250 [03:06<00:00,  1.34it/s, Loss=0.0053, Avg Loss=0.0034]\\n\",\"Epoch 36/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.42it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 035:\\n\",\"  Loss: 0.0034\\n\",\"  Dice: 0.9590\\n\",\"  Iou: 0.9432\\n\",\"  Precision: 0.9709\\n\",\"  Recall: 0.9690\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 36/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.34it/s, Loss=0.0038, Avg Loss=0.0034]\\n\",\"Epoch 37/40 [Val]: 100%|██████████| 63/63 [00:19<00:00,  3.25it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 036:\\n\",\"  Loss: 0.0034\\n\",\"  Dice: 0.9569\\n\",\"  Iou: 0.9407\\n\",\"  Precision: 0.9680\\n\",\"  Recall: 0.9691\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 37/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.33it/s, Loss=0.0042, Avg Loss=0.0035]\\n\",\"Epoch 38/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.54it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 037:\\n\",\"  Loss: 0.0035\\n\",\"  Dice: 0.9534\\n\",\"  Iou: 0.9390\\n\",\"  Precision: 0.9658\\n\",\"  Recall: 0.9693\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 38/40 [Train]: 100%|██████████| 250/250 [03:06<00:00,  1.34it/s, Loss=0.0051, Avg Loss=0.0034]\\n\",\"Epoch 39/40 [Val]: 100%|██████████| 63/63 [00:18<00:00,  3.40it/s, Avg Dice=0.0000]\\n\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 038:\\n\",\"  Loss: 0.0034\\n\",\"  Dice: 0.9604\\n\",\"  Iou: 0.9442\\n\",\"  Precision: 0.9754\\n\",\"  Recall: 0.9657\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"Epoch 39/40 [Train]: 100%|██████████| 250/250 [03:07<00:00,  1.33it/s, Loss=0.0035, Avg Loss=0.0034]\\n\",\"Epoch 40/40 [Val]: 100%|██████████| 63/63 [00:17<00:00,  3.59it/s, Avg Dice=0.0000]\"]},{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Epoch 039:\\n\",\"  Loss: 0.0034\\n\",\"  Dice: 0.9549\\n\",\"  Iou: 0.9415\\n\",\"  Precision: 0.9695\\n\",\"  Recall: 0.9685\\n\",\"  LR:   2.00e-04\\n\",\"----------------------------------------\\n\"]},{\"output_type\":\"stream\",\"name\":\"stderr\",\"text\":[\"\\n\"]}],\"execution_count\":34},{\"cell_type\":\"code\",\"source\":[\"!git clone https://github.com/MiniRedTrout/Segmentation.git\\n\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"mBOyGlioVOvw\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763476028007,\"user_tz\":-180,\"elapsed\":2383,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}},\"outputId\":\"b195c4dd-efcd-47d5-a68f-229dab682d1d\"},\"execution_count\":64,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"Cloning into 'Segmentation'...\\n\",\"remote: Enumerating objects: 9, done.\\u001b[K\\n\",\"remote: Counting objects: 100% (9/9), done.\\u001b[K\\n\",\"remote: Compressing objects: 100% (8/8), done.\\u001b[K\\n\",\"remote: Total 9 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\\u001b[K\\n\",\"Receiving objects: 100% (9/9), 8.75 MiB | 9.47 MiB/s, done.\\n\",\"Resolving deltas: 100% (1/1), done.\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"%cd Segmentation\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"t7KHRK25WHVu\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763476046969,\"user_tz\":-180,\"elapsed\":16,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}},\"outputId\":\"7a92f41a-df29-4304-f232-2c257e8dbcb4\"},\"execution_count\":65,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"/content/Segmentation/Segmentation/Segmentation/Segmentation\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"!cp /content/drive/MyDrive/ColabNotebooks/notebook4e08fe2ac5.ipynb /content/Segmentation/notebook4e08fe2ac5.ipynb\"],\"metadata\":{\"id\":\"Pmt-vP6_XQLj\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763476458043,\"user_tz\":-180,\"elapsed\":1159,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}}},\"execution_count\":75,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"!git config --global user.email \\\"enemydoctor@gmail.com\\\"\\n\",\"!git config --global user.name \\\"MiniRedTrout\\\"\"],\"metadata\":{\"id\":\"xdrYXyFuXpYr\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763476460066,\"user_tz\":-180,\"elapsed\":175,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}}},\"execution_count\":76,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"!git status\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"aRAiMXr3Yd9_\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763476461399,\"user_tz\":-180,\"elapsed\":151,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}},\"outputId\":\"86adb611-b867-4da3-ae8c-934630944cdd\"},\"execution_count\":77,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"On branch main\\n\",\"Your branch is up to date with 'origin/main'.\\n\",\"\\n\",\"nothing to commit, working tree clean\\n\"]}]},{\"cell_type\":\"code\",\"source\":[\"!git diff notebook4e08fe2ac5.ipynb\"],\"metadata\":{\"id\":\"H4oJXlp1YfyV\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763476397649,\"user_tz\":-180,\"elapsed\":118,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}}},\"execution_count\":72,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"!git add notebook4e08fe2ac5.ipynb\"],\"metadata\":{\"id\":\"TOLqAfpgYlwz\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763476418781,\"user_tz\":-180,\"elapsed\":106,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}}},\"execution_count\":73,\"outputs\":[]},{\"cell_type\":\"code\",\"source\":[\"!git commit -m \\\"Update notebook4e08fe2ac5\\\"\"],\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"s4HxBQwRYq6z\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1763476447148,\"user_tz\":-180,\"elapsed\":109,\"user\":{\"displayName\":\"Enemy Doctor\",\"userId\":\"03542272126648171634\"}},\"outputId\":\"709dff01-c72f-4d9b-b211-6d0980d7cfb2\"},\"execution_count\":74,\"outputs\":[{\"output_type\":\"stream\",\"name\":\"stdout\",\"text\":[\"On branch main\\n\",\"Your branch is up to date with 'origin/main'.\\n\",\"\\n\",\"nothing to commit, working tree clean\\n\"]}]},{\"cell_type\":\"code\",\"source\":[],\"metadata\":{\"id\":\"yvvcEUTeYx2s\"},\"execution_count\":null,\"outputs\":[]}]}\u001b[m\n",
            "\\ No newline at end of file\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add notebook4e08fe2ac5.ipynb"
      ],
      "metadata": {
        "id": "TOLqAfpgYlwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Update notebook4e08fe2ac5\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4HxBQwRYq6z",
        "outputId": "c750818b-996a-468c-a755-c00fb4ae2e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 43e52bf] Update notebook4e08fe2ac5\n",
            " 1 file changed, 1 insertion(+), 979 deletions(-)\n",
            " rewrite notebook4e08fe2ac5.ipynb (98%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ssh-keygen -t rsa -b 4096 -C \"enemydoctor@gmail.com\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvvcEUTeYx2s",
        "outputId": "af9f7959-3281-405c-f12a-7f34aef8db17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating public/private rsa key pair.\n",
            "Enter file in which to save the key (/root/.ssh/id_rsa): \n",
            "Enter passphrase (empty for no passphrase): \n",
            "Enter same passphrase again: \n",
            "Your identification has been saved in /root/.ssh/id_rsa\n",
            "Your public key has been saved in /root/.ssh/id_rsa.pub\n",
            "The key fingerprint is:\n",
            "SHA256:8KNe4uyo4DQpATx87EVx3RgUM5TFtNpBjYYoxecWAXI enemydoctor@gmail.com\n",
            "The key's randomart image is:\n",
            "+---[RSA 4096]----+\n",
            "|     ++E*O%+o    |\n",
            "|o . ..+o B+=..   |\n",
            "|.+ o .o o oo     |\n",
            "|. + .  o oo .    |\n",
            "|.  .    S. .     |\n",
            "| ..    . .       |\n",
            "|o+    o .        |\n",
            "|+..  = o         |\n",
            "| .....=          |\n",
            "+----[SHA256]-----+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ssh-keyscan github.com >> /root/.ssh/know_hosts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxuZCbfMaie2",
        "outputId": "f82aebd6-acb5-4f7e-d344-4f354e2fa583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# github.com:22 SSH-2.0-5554dfa\n",
            "# github.com:22 SSH-2.0-5554dfa\n",
            "# github.com:22 SSH-2.0-5554dfa\n",
            "# github.com:22 SSH-2.0-5554dfa\n",
            "# github.com:22 SSH-2.0-5554dfa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone git@github.com:MiniRedTrout/Segmentation.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSN8EgIBcF5H",
        "outputId": "205c4045-5736-461e-e6c6-001688d18970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Segmentation' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lytInT6NcQMI",
        "outputId": "468068ad-afd3-4026-f90e-4701ffb7d5ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Permission to MiniRedTrout/Segmentation.git denied to MiniRedTrout.\n",
            "fatal: unable to access 'https://github.com/MiniRedTrout/Segmentation.git/': The requested URL returned error: 403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CqRTqS2FcTaG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}